import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
from datetime import datetime, timedelta
import numpy as np
import time
import json
from pathlib import Path
import requests
import zipfile
import os
import tempfile
from typing import List, Dict, Optional
import hashlib

from langchain_community.document_loaders import PyPDFLoader, TextLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_ollama import OllamaLLM
from langchain.chains import RetrievalQA
from langchain_core.prompts import PromptTemplate
from langchain.schema import Document

class DocumentaryResourceManager:
    def __init__(self, cache_dir="cache/regulatory_sources"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        
        self.downloaded_docs_dir = self.cache_dir / "downloaded_pdfs"
        self.downloaded_docs_dir.mkdir(parents=True, exist_ok=True)
        
        self.metadata_file = self.cache_dir / "download_metadata.json"
        
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
        
        self.download_metadata = self._load_download_metadata()
    
    def _load_download_metadata(self) -> dict:
        if self.metadata_file.exists():
            try:
                with open(self.metadata_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur lecture m√©tadonn√©es: {e}")
        return {"downloads": {}, "last_update": None}
    
    def _save_download_metadata(self):
        try:
            from datetime import datetime
            self.download_metadata["last_update"] = datetime.now().isoformat()
            with open(self.metadata_file, 'w', encoding='utf-8') as f:
                json.dump(self.download_metadata, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"‚ö†Ô∏è Erreur sauvegarde m√©tadonn√©es: {e}")
    
    def load_local_documents(self, documents_path="training_corpus") -> List[Document]:
        st.info("üìÅ Chargement depuis training_corpus/...")
        
        local_docs = []
        documents_path = Path(documents_path)
        
        if not documents_path.exists():
            st.warning(f"üìÇ Dossier {documents_path} non trouv√©")
            return []
        
        pdf_files = list(documents_path.glob("*.pdf"))
        st.info(f"üìÑ Trouv√© {len(pdf_files)} PDFs dans {documents_path}")
        
        for pdf_file in pdf_files:
            try:
                loader = PyPDFLoader(str(pdf_file))
                docs = loader.load()
                
                filename_lower = pdf_file.name.lower()
                if "basel" in filename_lower or "bale" in filename_lower:
                    document_type = "regulatory_framework"
                    authority = "Basel Committee (BEAC Training)"
                    topic = "operational_risk_basel"
                elif "coso" in filename_lower:
                    document_type = "control_framework" 
                    authority = "COSO Framework (BEAC Training)"
                    topic = "internal_control"
                elif "demaris" in filename_lower:
                    document_type = "methodology"
                    authority = "DEMARIS Methodology (BEAC)"
                    topic = "demaris_framework"
                else:
                    document_type = "training_document"
                    authority = "BEAC Formation"
                    topic = "general_training"
                
                for doc in docs:
                    doc.metadata.update({
                        'filename': pdf_file.name,
                        'source_type': document_type,
                        'file_path': str(pdf_file),
                        'document_type': document_type,
                        'authority': authority,
                        'topic': topic,
                        'source': f"LOCAL_{pdf_file.stem.upper()}"
                    })
                
                local_docs.extend(docs)
                st.success(f"‚úÖ Charg√©: {pdf_file.name} ({len(docs)} pages)")
                
            except Exception as e:
                st.warning(f"‚ùå Erreur lecture {pdf_file.name}: {e}")
        
        if local_docs:
            st.success(f"‚úÖ Total charg√©: {len(local_docs)} pages depuis vos documents")
        else:
            st.warning("‚ö†Ô∏è Aucun document charg√© depuis training_corpus")
            st.info("""
            üí° **V√©rifiez que vous avez des fichiers PDF dans :**
            training_corpus/basel_ii_operational.pdf
            training_corpus/coso_framework.pdf  
            training_corpus/demaris_methodolo.pdf
            """)
            
        return local_docs
    
    def get_all_documents(self, include_local=True, force_download: bool = False) -> List[Document]:
        all_documents = []
        
        if include_local:
            local_docs = self.load_local_documents()
            all_documents.extend(local_docs)
            st.success(f"‚úÖ Documents locaux charg√©s: {len(all_documents)}")
        else:
            st.info("üìÅ Chargement local d√©sactiv√©")
        
        return all_documents
    
    def get_download_statistics(self) -> dict:
        stats = {
            "total_downloads": len(self.download_metadata["downloads"]),
            "last_update": self.download_metadata.get("last_update"),
            "downloads_by_source": {},
            "total_size_mb": 0,
            "local_docs_count": 0
        }
        
        for download in self.download_metadata["downloads"].values():
            filename = download["filename"].lower()
            if "bis" in filename or "basel" in filename:
                source = "BIS"
            elif "eba" in filename:
                source = "EBA"
            elif "ecb" in filename or "imf" in filename or "fed" in filename:
                source = "Academic"
            else:
                source = "Other"
            
            stats["downloads_by_source"][source] = stats["downloads_by_source"].get(source, 0) + 1
            stats["total_size_mb"] += download.get("file_size", 0) / (1024 * 1024)
        
        documents_path = Path("training_corpus")
        if documents_path.exists():
            stats["local_docs_count"] = len(list(documents_path.glob("*.pdf")))
        
        return stats

ENHANCED_VERIFIED_ANSWERS = {
    "ama": """**AMA (Advanced Measurement Approach)**

L'Approche de Mesure Avanc√©e (AMA) est une m√©thode sophistiqu√©e pour calculer les exigences de fonds propres au titre du risque op√©rationnel selon B√¢le II/III.

**Caract√©ristiques principales :**
- Utilise les mod√®les internes de la banque valid√©s par les superviseurs
- Bas√©e sur au minimum 5 ans de donn√©es historiques de pertes
- Int√®gre les facteurs de risque prospectifs via l'analyse de sc√©narios
- N√©cessite l'approbation explicite des autorit√©s de supervision

**Quatre composants obligatoires :**
1. **Donn√©es de pertes internes** - Historique d√©taill√© des incidents (‚â•5 ans)
2. **Donn√©es externes** - Bases de donn√©es sectorielles et consortiums
3. **Analyse de sc√©narios** - √âvaluation prospective d'√©v√©nements extr√™mes
4. **Facteurs d'environnement de contr√¥le** - Qualit√© du contr√¥le interne (BEICFs)

**Crit√®res quantitatifs :**
- Seuil de collecte : ‚Ç¨20,000 pour les pertes brutes
- P√©riode d'observation minimale : 5 ans
- Confiance : 99.9% sur horizon 1 an
- Corr√©lations entre risques prises en compte

**Crit√®res qualitatifs :**
- Gouvernance robuste et ind√©pendance de la fonction risque op√©rationnel
- Int√©gration dans la gestion quotidienne des risques
- Validation r√©guli√®re des mod√®les et back-testing
- Documentation compl√®te des m√©thodologies

*Source : B√¢le II/III, EBA Guidelines on AMA*""",

    "piliers_bale": """**Les Trois Piliers de B√¢le III**

**PILIER 1 - Exigences minimales de fonds propres renforc√©es**

*Capital de base (CET1 - Common Equity Tier 1) :*
- Ratio CET1 minimum : 4,5% des actifs pond√©r√©s des risques
- Coussin de conservation : 2,5% suppl√©mentaires
- Coussin contracyclique : 0% √† 2,5% selon le cycle √©conomique
- Surcharge syst√©mique : 1% √† 3,5% pour les banques G-SIB

*Couverture des risques :*
- Risque de cr√©dit (approches standardis√©e/IRB)
- Risque de march√© (m√©thode standard/mod√®les internes)
- Risque op√©rationnel (BIA/TSA/AMA ‚Üí SA sous B√¢le IV)

**PILIER 2 - Processus de surveillance prudentielle**

*ICAAP (Internal Capital Adequacy Assessment Process) :*
- √âvaluation interne de l'ad√©quation des fonds propres
- Stress tests et analyses de sc√©narios
- Gouvernance des risques et app√©tit pour le risque
- Capital pour risques non couverts par le Pilier 1

*SREP (Supervisory Review and Evaluation Process) :*
- Examen superviseur des pratiques bancaires
- Validation des mod√®les internes et m√©thodologies
- Fixation d'exigences de capital individuelles
- Mesures correctives si n√©cessaire

**PILIER 3 - Discipline de march√© et transparence**

*Obligations de communication :*
- Rapport Pilier 3 semestriel/annuel d√©taill√©
- Informations sur l'ad√©quation des fonds propres
- Exposition aux risques par type et g√©ographie
- M√©thodologies de mesure et de gestion des risques
- Ratios prudentiels et indicateurs de solidit√©

*Objectifs :*
- Renforcer la confiance des march√©s financiers
- Permettre aux investisseurs d'√©valuer les risques
- Encourager les bonnes pratiques de gestion
- Compl√©ter la supervision r√©glementaire

*Source : Accords de B√¢le III, R√®glement CRR/CRD IV*""",

    "coso": """**COSO (Committee of Sponsoring Organizations)**

Le **Committee of Sponsoring Organizations of the Treadway Commission** a d√©velopp√© le r√©f√©rentiel de contr√¥le interne le plus utilis√© mondialement, adopt√© par les r√©gulateurs bancaires et d'assurance.

**Les 5 Composants du Contr√¥le Interne COSO 2013 :**

**1. Environnement de contr√¥le** 
- Int√©grit√© et valeurs √©thiques d√©montr√©es par la direction
- Ind√©pendance du conseil d'administration et surveillance efficace
- Structure organisationnelle claire et attribution des responsabilit√©s
- Comp√©tences professionnelles et d√©veloppement du personnel
- Redevabilit√© en mati√®re de performance et mesures correctives

**2. √âvaluation des risques**
- Sp√©cification d'objectifs clairs et coh√©rents
- Identification et analyse des risques mena√ßant les objectifs
- √âvaluation du risque de fraude dans tous ses aspects
- Identification et √©valuation des changements significatifs
- Analyse de l'impact et de la probabilit√© des risques

**3. Activit√©s de contr√¥le**
- S√©lection et d√©veloppement d'activit√©s de contr√¥le appropri√©es
- Contr√¥les g√©n√©raux informatiques et contr√¥les applicatifs
- D√©ploiement des contr√¥les via des politiques et proc√©dures
- S√©paration des t√¢ches et autorisations appropri√©es
- Supervision directe et revues de performance

**4. Information et communication**
- Utilisation d'informations pertinentes et de qualit√©
- Communication interne des responsabilit√©s de contr√¥le
- Communication externe avec les parties prenantes
- Syst√®mes d'information soutenant le contr√¥le interne
- Canaux de communication pour signaler les d√©ficiences

**5. Activit√©s de pilotage (Monitoring)**
- S√©lection, d√©veloppement et r√©alisation d'√©valuations continues
- √âvaluations ponctuelles pour confirmer l'efficacit√©
- Communication des d√©ficiences de contr√¥le interne
- Suivi de la mise en ≈ìuvre des actions correctives
- Assurance qualit√© et am√©lioration continue

**17 Principes sous-jacents :**
Chaque composant est soutenu par des principes sp√©cifiques qui, lorsqu'ils sont pr√©sents et fonctionnent ensemble, permettent de conclure que les cinq composants sont efficaces.

**Applications r√©glementaires :**
- SOX 404 (√âtats-Unis) - Contr√¥les financiers
- AMF (France) - Contr√¥le interne des soci√©t√©s cot√©es  
- Solvabilit√© II (UE) - Syst√®me de gouvernance des assureurs
- B√¢le III - Gouvernance des risques bancaires

*Source : COSO Framework 2013, ERM Framework 2017*""",

    "risque_operationnel": """**Risque Op√©rationnel - D√©finition et Framework R√©glementaire**

**D√©finition Officielle (B√¢le III) :**
Le risque op√©rationnel est d√©fini comme *"le risque de perte r√©sultant de processus internes inad√©quats ou d√©faillants, de personnes et de syst√®mes ou d'√©v√©nements externes"*. Cette d√©finition inclut le risque juridique mais exclut les risques strat√©giques et de r√©putation.

**Taxonomie des Risques Op√©rationnels :**

**1. Risques de Processus :**
- Inad√©quation ou d√©faillance des processus m√©tier
- Erreurs dans l'ex√©cution, la livraison et la gestion des processus
- Complexit√© excessive et manque de standardisation
- D√©faillances dans les contr√¥les et la supervision

**2. Risques de Personnel :**
- Erreur humaine, n√©gligence ou incomp√©tence
- Fraude interne et malveillance
- Violations des politiques internes et r√©glementations
- Probl√®mes de ressources humaines et relations sociales
- Sant√© et s√©curit√© au travail

**3. Risques de Syst√®mes :**
- Pannes et d√©faillances des syst√®mes informatiques
- Cyberattaques et s√©curit√© informatique
- Int√©grit√© et qualit√© des donn√©es
- Obsolescence technologique
- Indisponibilit√© des syst√®mes critiques

**4. Risques Externes :**
- Catastrophes naturelles et √©v√©nements m√©t√©orologiques
- Actes de terrorisme et troubles civils
- D√©faillances d'infrastructures externes (√©nergie, t√©l√©coms)
- √âvolutions r√©glementaires d√©favorables
- Risques g√©opolitiques et sanctions

**Cat√©gories d'√âv√©nements B√¢le (Level 1) :**
1. Fraude interne
2. Fraude externe  
3. Pratiques en mati√®re d'emploi et s√©curit√© du lieu de travail
4. Pratiques avec la client√®le, produits et services
5. Dommages aux biens
6. Dysfonctionnement de l'activit√© et d√©faillance des syst√®mes
7. Ex√©cution, livraison et gestion des processus

**Framework de Gestion :**

**Gouvernance :**
- App√©tit et tol√©rance au risque d√©finis par le conseil
- Fonction risque op√©rationnel ind√©pendante
- Mod√®le des trois lignes de d√©fense
- Reporting r√©gulier au management et au conseil

**Identification et √âvaluation :**
- Cartographie des risques par processus m√©tier
- Auto-√©valuations des risques et contr√¥les (RCSA)
- Collecte et analyse des donn√©es de pertes
- Indicateurs cl√©s de risque (KRI) et alertes pr√©coces

**Ma√Ætrise et Att√©nuation :**
- Plans de continuit√© d'activit√© (PCA/BCP)
- Contr√¥les pr√©ventifs, d√©tectifs et correctifs
- Transfert de risque (assurance, externalisation)
- Formation et sensibilisation du personnel

**Surveillance et Reporting :**
- Monitoring continu des expositions et contr√¥les
- Reporting d'incidents et analyse des causes racines
- Tests de r√©sistance (stress testing)
- Validation ind√©pendante par l'audit interne

*Source : B√¢le III, EBA Guidelines, Solvabilit√© II*"""
}

def enhanced_get_verified_answer(question: str, retrieved_context: List[Document]) -> Optional[str]:
    question_lower = question.lower()
    
    if any(kw in question_lower for kw in ['ama', 'advanced measurement', 'mesure avanc√©e', 'approche de mesure']):
        return ENHANCED_VERIFIED_ANSWERS["ama"]
    elif any(kw in question_lower for kw in ['pilier', 'piliers', 'b√¢le', 'basel', 'bale']) and any(kw in question_lower for kw in ['trois', '3', 'iii']):
        return ENHANCED_VERIFIED_ANSWERS["piliers_bale"]
    elif any(kw in question_lower for kw in ['coso', 'contr√¥le interne', 'control', 'committee sponsoring']):
        return ENHANCED_VERIFIED_ANSWERS["coso"]
    elif any(kw in question_lower for kw in ['risque op√©rationnel', 'operational risk', 'risques op√©rationnels']):
        return ENHANCED_VERIFIED_ANSWERS["risque_operationnel"]
    
    return None

def enhanced_validate_response(response: str, question: str, context_sources: List[str]) -> List[str]:
    response_lower = response.lower()
    question_lower = question.lower()
    
    hallucinations_detected = []
    
    critical_suspicious_phrases = [
        "je ne peux pas r√©pondre", "je ne sais vraiment pas", "aucune information disponible",
        "impossible de r√©pondre", "donn√©es insuffisantes"
    ]
    
    if len(response) < 100 and any(phrase in response_lower for phrase in critical_suspicious_phrases):
        hallucinations_detected.append("R√©ponse trop vague ou refus injustifi√©")
    
    if 'ama' in question_lower and 'cr√©dit' in response_lower and 'op√©rationnel' not in response_lower:
        hallucinations_detected.append("Confusion AMA/Cr√©dit grave")
    
    if 'coso' in question_lower and 'basel' in response_lower and 'contr√¥le interne' not in response_lower:
        hallucinations_detected.append("Confusion COSO/Basel grave")
    
    if len(response) > 200 and context_sources:
        return []
    
    return hallucinations_detected

class EnhancedSafeDemarisQA:
    def __init__(self, qa_chain, resource_manager=None):
        self.qa_chain = qa_chain
        self.resource_manager = resource_manager
    
    def invoke(self, inputs):
        question = inputs.get("query", "")
        
        if self.qa_chain is None:
            verified_answer = enhanced_get_verified_answer(question, [])
            if verified_answer:
                return {
                    "result": verified_answer,
                    "source_documents": []
                }
            else:
                return {
                    "result": f"Information sur '{question}' non disponible. Syst√®me DEMARIS en mode d√©grad√© - ressources documentaires non charg√©es.",
                    "source_documents": []
                }
        
        result = self.qa_chain.invoke(inputs)
        retrieved_context = result.get("source_documents", [])
        
        verified_answer = enhanced_get_verified_answer(question, retrieved_context)
        if verified_answer:
            return {
                "result": verified_answer,
                "source_documents": retrieved_context
            }
        
        generated_response = result["result"]
        context_sources = [doc.metadata.get("source", "") for doc in retrieved_context]
        
        authoritative_sources = [src for src in context_sources if any(auth in src for auth in ['BIS_', 'EBA_', 'DATASET_', 'LOCAL_'])]
        
        if len(generated_response) > 150 and len(authoritative_sources) > 0:
            critical_hallucinations = enhanced_validate_response(generated_response, question, context_sources)
            
            if not critical_hallucinations:
                enhanced_response = f"{generated_response}\n\n*Sources consult√©es : {', '.join(set(authoritative_sources[:3]))}*"
                return {
                    "result": enhanced_response,
                    "source_documents": retrieved_context
                }
        
        if len(generated_response) < 100:
            return {
                "result": f"Les documents consult√©s ne contiennent pas suffisamment d'informations d√©taill√©es sur '{question}'. Recommandation : reformuler la question ou consulter directement les sources r√©glementaires officielles (Basel Committee, EBA).",
                "source_documents": retrieved_context
            }
        
        return {
            "result": f"{generated_response}\n\n*‚ö†Ô∏è R√©ponse bas√©e sur les documents disponibles - validation recommand√©e avec sources officielles*",
            "source_documents": retrieved_context
        }

def create_enhanced_demaris(force_reload: bool = False):
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    status_text.text("üîß Initialisation du gestionnaire de ressources...")
    progress_bar.progress(10)
    
    resource_manager = DocumentaryResourceManager()
    
    all_documents = []
    vectorstore_path = Path("cache/local_demaris_vectorstore")
    
    if not vectorstore_path.exists() or force_reload:
        status_text.text("üìÅ Chargement des documents depuis training_corpus/...")
        progress_bar.progress(25)
        
        local_docs = resource_manager.load_local_documents()
        all_documents.extend(local_docs)
        
        if not all_documents:
            st.warning("‚ö†Ô∏è Aucun document trouv√© dans training_corpus/")
            st.info("""
            üìÇ **Placez vos documents directement dans :**
            training_corpus/basel_ii_operational.pdf
            training_corpus/coso_framework.pdf  
            training_corpus/demaris_methodolo.pdf
            """)
    else:
        status_text.text("üìÇ Utilisation du vectorstore local existant...")
        progress_bar.progress(25)
        st.info("Vectorstore local d√©tect√© - pas de rechargement.")

    embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
    
    if vectorstore_path.exists() and len(list(vectorstore_path.glob("*"))) > 0 and not force_reload:
        status_text.text("üìö Chargement du vectorstore existant...")
        progress_bar.progress(70)
        try:
            vectorstore = FAISS.load_local(
                str(vectorstore_path),
                embeddings,
                allow_dangerous_deserialization=True
            )
            st.success("‚úÖ Vectorstore charg√© avec succ√®s.")
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Erreur chargement vectorstore existant: {e}")
            vectorstore = None
    else:
        vectorstore = None
    
    if vectorstore is None and all_documents:
        status_text.text("üÜï Cr√©ation d'un nouveau vectorstore enrichi...")
        progress_bar.progress(85)
        
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len
        )
        
        all_split_docs = []
        for doc in all_documents:
            chunks = text_splitter.split_documents([doc])
            all_split_docs.extend(chunks)
        
        if all_split_docs:
            vectorstore = FAISS.from_documents(all_split_docs, embeddings)
            
            vectorstore_path.mkdir(parents=True, exist_ok=True)
            vectorstore.save_local(str(vectorstore_path))
            st.success(f"‚úÖ Nouveau vectorstore cr√©√© avec {len(all_split_docs)} chunks!")
    
    if vectorstore:
        status_text.text("ü§ñ Configuration du mod√®le QA...")
        progress_bar.progress(90)
        
        retriever = vectorstore.as_retriever(search_kwargs={"k": 8})
        
        llm = OllamaLLM(
            model="qwen2.5:0.5b-instruct-q4_K_M",
            temperature=0.05,
            top_p=0.3,
            top_k=5
        )
        
        local_prompt = """Tu es un assistant expert en r√©glementation bancaire et financi√®re.

INSTRUCTIONS :
1. Utilise PRIORITAIREMENT les informations de vos documents de formation ci-dessous
2. Donne des r√©ponses substantielles bas√©es sur les documents training_corpus
3. Si l'information est dans le contexte, R√âPONDS de mani√®re compl√®te
4. Mentionne le document source quand possible (Basel II, COSO, DEMARIS)
5. Structure ta r√©ponse clairement avec des sections

CONTEXTE DOCUMENTAIRE LOCAL :
{context}

QUESTION : {question}

R√âPONSE EXPERTE (bas√©e sur vos documents de formation) :"""
        
        base_qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=retriever,
            return_source_documents=True,
            chain_type_kwargs={
                "prompt": PromptTemplate(
                    template=local_prompt,
                    input_variables=["context", "question"]
                )
            }
        )
        
        safe_qa_chain = EnhancedSafeDemarisQA(base_qa_chain, resource_manager)
        
        status_text.text("‚úÖ Syst√®me DEMARIS enrichi pr√™t!")
        progress_bar.progress(100)
        
        return safe_qa_chain
        
    else:
        st.warning("‚ö†Ô∏è Aucun vectorstore disponible. Mode r√©ponses v√©rifi√©es uniquement.")
        progress_bar.progress(100)
        status_text.text("‚ö†Ô∏è Mode d√©grad√© activ√©")
        return EnhancedSafeDemarisQA(None, resource_manager)

def calculate_enhanced_metrics(question, response, start_time, end_time):
    try:
        try:
            import nltk
            from nltk.translate.bleu_score import sentence_bleu
        except ImportError:
            st.warning("‚ö†Ô∏è NLTK non disponible - m√©triques simplifi√©es")
            return {
                'rouge1': 0.5,
                'rougeL': 0.5,
                'bleu': 0.5,
                'similarity': 0.5,
                'faithfulness': 0.5,
                'relevance': 0.5,
                'response_time': end_time - start_time
            }
        
        try:
            from rouge_score import rouge_scorer
        except ImportError:
            st.warning("‚ö†Ô∏è Rouge-score non disponible - m√©triques simplifi√©es")
            return {
                'rouge1': 0.5,
                'rougeL': 0.5,
                'bleu': 0.5,
                'similarity': 0.5,
                'faithfulness': 0.5,
                'relevance': 0.5,
                'response_time': end_time - start_time
            }
        
        try:
            from sentence_transformers import SentenceTransformer
            from sklearn.metrics.pairwise import cosine_similarity
        except ImportError:
            st.warning("‚ö†Ô∏è Sentence-transformers non disponible - m√©triques simplifi√©es")
            return {
                'rouge1': 0.5,
                'rougeL': 0.5,
                'bleu': 0.5,
                'similarity': 0.5,
                'faithfulness': 0.5,
                'relevance': 0.5,
                'response_time': end_time - start_time
            }
        
        try:
            nltk.data.find('tokenizers/punkt')
        except LookupError:
            nltk.download('punkt', quiet=True)
        
        enhanced_references = {
            "ama": "L'Advanced Measurement Approach AMA est une m√©thode pour calculer les exigences de fonds propres pour le risque op√©rationnel selon B√¢le II avec mod√®les internes donn√©es historiques analyse sc√©narios facteurs environnement contr√¥le validation superviseurs",
            "coso": "COSO Committee of Sponsoring Organizations framework contr√¥le interne cinq composants environnement contr√¥le √©valuation risques activit√©s contr√¥le information communication pilotage monitoring",
            "piliers_bale": "Trois piliers B√¢le III pilier un exigences minimales fonds propres pilier deux processus surveillance prudentielle ICAAP SREP pilier trois discipline march√© transparence communication",
            "risque_operationnel": "Risque op√©rationnel risque de perte processus internes inad√©quats d√©faillants personnes syst√®mes √©v√©nements externes fraude interne externe dommages biens dysfonctionnement activit√©"
        }
        
        question_lower = question.lower()
        reference = None
        
        if 'ama' in question_lower:
            reference = enhanced_references["ama"]
        elif any(kw in question_lower for kw in ['coso', 'contr√¥le interne']):
            reference = enhanced_references["coso"]
        elif any(kw in question_lower for kw in ['pilier', 'b√¢le', 'basel']):
            reference = enhanced_references["piliers_bale"]
        elif 'risque op√©rationnel' in question_lower:
            reference = enhanced_references["risque_operationnel"]
        else:
            reference = question.lower().replace('?', '').replace('qu\'est-ce que', '').replace('quelle est', '')
        
        scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)
        rouge_scores = scorer.score(reference, response)
        rouge1 = rouge_scores['rouge1'].fmeasure
        rougeL = rouge_scores['rougeL'].fmeasure
        
        reference_tokens = reference.split()
        response_tokens = response.split()
        bleu = sentence_bleu([reference_tokens], response_tokens)
        
        model = SentenceTransformer('all-MiniLM-L6-v2')
        ref_embedding = model.encode([reference])
        resp_embedding = model.encode([response])
        similarity = cosine_similarity(ref_embedding, resp_embedding)[0][0]
        
        technical_terms = ['b√¢le', 'basel', 'pilier', 'capital', 'risque', 'ama', 'coso', 'contr√¥le', 
                          'r√©glementaire', 'prudentielle', 'supervision', 'op√©rationnel', 'framework']
        
        response_lower = response.lower()
        found_terms = sum(1 for term in technical_terms if term in response_lower)
        faithfulness = min(found_terms / len(technical_terms), 1.0)
        
        question_words = set(question.lower().split())
        response_words = set(response.lower().split())
        relevance = len(question_words.intersection(response_words)) / len(question_words) if question_words else 0
        
        return {
            'rouge1': float(rouge1),
            'rougeL': float(rougeL),
            'bleu': float(bleu),
            'similarity': float(similarity),
            'faithfulness': float(faithfulness),
            'relevance': float(relevance),
            'response_time': end_time - start_time
        }
        
    except Exception as e:
        st.warning(f"Erreur calcul m√©triques enrichies: {e}")
        return {
            'rouge1': 0.0,
            'rougeL': 0.0,
            'bleu': 0.0,
            'similarity': 0.0,
            'faithfulness': 0.0,
            'relevance': 0.0,
            'response_time': end_time - start_time
        }

def main():
    st.set_page_config(
        page_title="DEMARIS Pro - Assistant Local BEAC",
        page_icon="üè¶",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    st.markdown("""
    <style>
    .main-header {
        background: linear-gradient(90deg, #1f4e79 0%, #2e8bc0 100%);
        padding: 2rem;
        border-radius: 10px;
        margin-bottom: 2rem;
        text-align: center;
        color: white;
    }
    .metric-card {
        background: white;
        padding: 1rem;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        border-left: 4px solid #2e8bc0;
    }
    .chat-message {
        padding: 1rem;
        border-radius: 10px;
        margin: 1rem 0;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    .user-message {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
    }
    .bot-message {
        background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
        color: white;
    }
    </style>
    """, unsafe_allow_html=True)
    
    st.markdown("""
    <div class="main-header">
        <h1>üè¶ DEMARIS Pro - RAG Chatbot Local</h1>
        <p>Assistant Expert en R√©glementation Bancaire - Documents de Formation BEAC</p>
    </div>
    """, unsafe_allow_html=True)
    
    st.sidebar.title("üîß Navigation DEMARIS")
    
    if st.sidebar.button("üè† Retour Accueil Principal", use_container_width=True, type="secondary"):
        if 'redirect_to' in st.session_state:
            del st.session_state.redirect_to
        st.session_state.current_page = 'accueil'
        st.session_state.chatbot_subpage = None
        st.rerun()

    st.sidebar.markdown("---")
    
    if st.sidebar.button("üí¨ Chat Expert", use_container_width=True):
        st.session_state.current_page = "chat"
    
    if st.sidebar.button("üìä Tableau de Bord", use_container_width=True):
        st.session_state.current_page = "dashboard"
    
    if st.sidebar.button("üîç Sources Documentaires", use_container_width=True):
        st.session_state.current_page = "sources"
    
    if 'current_page' not in st.session_state:
        st.session_state.current_page = "chat"
    
    if st.session_state.current_page == "chat":
        page = "üí¨ Chat Expert"
    elif st.session_state.current_page == "dashboard":
        page = "üìä Tableau de Bord Enrichi"
    elif st.session_state.current_page == "sources":
        page = "üîç Sources Documentaires"
    else:
        page = "üí¨ Chat Expert"
    
    st.sidebar.markdown(f"**Page actuelle :** {page}")
    
    st.sidebar.markdown("---")
    st.sidebar.markdown("### üìä √âtat du Syst√®me")
    
    if 'enhanced_demaris_qa' in st.session_state:
        st.sidebar.success("‚úÖ DEMARIS Pro Actif")
    else:
        st.sidebar.warning("‚è≥ Initialisation...")
    
    if st.session_state.get('metrics_history'):
        st.sidebar.info(f"üìà {len(st.session_state.metrics_history)} questions trait√©es")
    
    if st.session_state.get('chat_history'):
        last_chat = st.session_state.chat_history[-1]
        st.sidebar.caption(f"üïê Derni√®re question: {last_chat['timestamp'].strftime('%H:%M:%S')}")
    
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ‚öôÔ∏è Actions Rapides")
    
    if st.sidebar.button("üóëÔ∏è Vider Cache", help="Effacer historique et m√©triques"):
        st.session_state.chat_history = []
        st.session_state.metrics_history = []
        st.sidebar.success("Cache vid√© !")
        st.rerun()
    
    if st.sidebar.button("üîÑ Recharger Syst√®me", help="Recharger DEMARIS Pro avec nouvelles donn√©es"):
        if 'enhanced_demaris_qa' in st.session_state:
            del st.session_state.enhanced_demaris_qa
        st.session_state.enhanced_demaris_qa = create_enhanced_demaris(force_reload=True)
        st.rerun()
    
    if 'enhanced_demaris_qa' not in st.session_state:
        with st.spinner("üöÄ Initialisation du syst√®me DEMARIS enrichi..."):
            st.session_state.enhanced_demaris_qa = create_enhanced_demaris()
    
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    if 'metrics_history' not in st.session_state:
        st.session_state.metrics_history = []
    
    if page == "üí¨ Chat Expert":
        show_enhanced_chat()
    elif page == "üìä Tableau de Bord Enrichi":
        show_enhanced_dashboard()
    elif page == "üîç Sources Documentaires":
        show_documentation_sources()

def show_enhanced_chat():
    st.header("üí¨ Chat Expert DEMARIS")
    
    col1, col2, col3, col4 = st.columns([2, 1, 1, 1])
    
    with col1:
        st.info("üéØ **Documents de formation :** Basel II Operational, COSO Framework, DEMARIS Methodology")
    
    with col2:
        if st.button("üìä Voir Dashboard", type="secondary", use_container_width=True):
            st.session_state.current_page = "dashboard"
            st.rerun()
    
    with col3:
        if st.button("üîç Sources", type="secondary", use_container_width=True):
            st.session_state.current_page = "sources"
            st.rerun()
    
    with col4:
        if st.button("üóëÔ∏è Effacer", type="secondary", use_container_width=True):
            st.session_state.chat_history = []
            st.session_state.metrics_history = []
            st.rerun()
    
    if st.session_state.get('metrics_history'):
        col1, col2, col3, col4 = st.columns(4)
        latest = st.session_state.metrics_history[-1]
        
        with col1:
            st.metric("üéØ Pr√©cision", f"{latest['rouge1']:.3f}")
        with col2:
            st.metric("üß† Similarit√©", f"{latest['similarity']:.3f}")
        with col3:
            st.metric("‚ö° Temps", f"{latest['response_time']:.1f}s")
        with col4:
            st.metric("üí¨ Questions", len(st.session_state.metrics_history))
        
        st.markdown("---")
    
    user_question = st.text_input(
        "ü§î Posez votre question r√©glementaire :",
        placeholder="Ex: Qu'est-ce que l'approche AMA pour le risque op√©rationnel ?"
    )
    
    if st.button("üì§ Envoyer", type="primary") and user_question:
        with st.spinner("üîç Consultation des sources r√©glementaires enrichies..."):
            start_time = time.time()
            
            response = st.session_state.enhanced_demaris_qa.invoke({"query": user_question})
            answer = response["result"]
            sources = response.get("source_documents", [])
            
            end_time = time.time()
            
            metrics = calculate_enhanced_metrics(user_question, answer, start_time, end_time)
            
            st.session_state.chat_history.append({
                "question": user_question,
                "answer": answer,
                "timestamp": datetime.now(),
                "sources": len(sources),
                "source_details": [doc.metadata for doc in sources]
            })
            
            st.session_state.metrics_history.append({
                "timestamp": datetime.now(),
                "question": user_question,
                **metrics
            })
    
    st.markdown("---")
    st.subheader("üìö Historique des Consultations")
    
    for i, chat in enumerate(reversed(st.session_state.chat_history[-5:])):
        st.markdown(f"""
        <div class="chat-message user-message">
            <strong>ü§î Question {len(st.session_state.chat_history)-i} :</strong><br>
            {chat['question']}
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown(f"""
        <div class="chat-message bot-message">
            <strong>ü§ñ DEMARIS Pro :</strong><br>
            {chat['answer']}<br><br>
            <small>‚è±Ô∏è {chat['timestamp'].strftime('%H:%M:%S')} | üìÑ {chat['sources']} sources consult√©es</small>
        </div>
        """, unsafe_allow_html=True)

def show_enhanced_dashboard():
    col1, col2 = st.columns([3, 1])
    
    with col1:
        st.markdown("""
        <div style="background: linear-gradient(90deg, #1f4e79 0%, #2e8bc0 100%); padding: 1.5rem; border-radius: 10px; margin-bottom: 1rem;">
            <h1 style="color: white; margin: 0;">üìä Tableau de bord des performances</h1>
            <p style="color: white; margin: 0; opacity: 0.9;">M√©triques de Qualit√© DEMARIS Pro</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        if st.button("‚Üê Retour au Chat", type="primary", use_container_width=True):
            st.session_state.current_page = "chat"
            st.rerun()
    
    if not st.session_state.metrics_history:
        st.info("üí° Aucune donn√©e disponible. Posez des questions dans le chat pour voir les m√©triques.")
        return
    
    st.markdown("## üìà M√©triques Temps R√©el")
    
    latest_metrics = st.session_state.metrics_history[-1]
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        delta_rouge = latest_metrics['rouge1'] - (st.session_state.metrics_history[-2]['rouge1'] if len(st.session_state.metrics_history) > 1 else 0)
        st.markdown(f"""
        <div class="metric-card">
            <h3>üéØ Score ROUGE-L</h3>
            <h2>{latest_metrics['rouge1']:.3f}</h2>
            <p style="color: {'green' if delta_rouge >= 0 else 'red'};">
                {'‚ÜóÔ∏è' if delta_rouge >= 0 else '‚ÜòÔ∏è'} {delta_rouge:+.3f}
            </p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        delta_bleu = latest_metrics['bleu'] - (st.session_state.metrics_history[-2]['bleu'] if len(st.session_state.metrics_history) > 1 else 0)
        st.markdown(f"""
        <div class="metric-card">
            <h3>üîµ Score BLEU</h3>
            <h2>{latest_metrics['bleu']:.3f}</h2>
            <p style="color: {'green' if delta_bleu >= 0 else 'red'};">
                {'‚ÜóÔ∏è' if delta_bleu >= 0 else '‚ÜòÔ∏è'} {delta_bleu:+.3f}
            </p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        delta_sim = latest_metrics['similarity'] - (st.session_state.metrics_history[-2]['similarity'] if len(st.session_state.metrics_history) > 1 else 0)
        st.markdown(f"""
        <div class="metric-card">
            <h3>üß† Similarit√© S√©mantique</h3>
            <h2>{latest_metrics['similarity']:.3f}</h2>
            <p style="color: {'green' if delta_sim >= 0 else 'red'};">
                {'‚ÜóÔ∏è' if delta_sim >= 0 else '‚ÜòÔ∏è'} {delta_sim:+.3f}
            </p>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        delta_time = latest_metrics['response_time'] - (st.session_state.metrics_history[-2]['response_time'] if len(st.session_state.metrics_history) > 1 else 0)
        st.markdown(f"""
        <div class="metric-card">
            <h3>‚ö° Temps de R√©ponse</h3>
            <h2>{latest_metrics['response_time']:.2f} secondes</h2>
            <p style="color: {'red' if delta_time >= 0 else 'green'};">
                {'‚ÜóÔ∏è' if delta_time >= 0 else '‚ÜòÔ∏è'} {delta_time:+.2f} secondes
            </p>
        </div>
        """, unsafe_allow_html=True)
    
    if len(st.session_state.metrics_history) > 1:
        history_df = pd.DataFrame(st.session_state.metrics_history)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("## üìä √âvolution des Scores de Qualit√©")
            
            fig = go.Figure()
            
            rouge1_unique = history_df['rouge1'].nunique()
            rougeL_unique = history_df['rougeL'].nunique()
            bleu_unique = history_df['bleu'].nunique()
            
            if rouge1_unique == 1 and rougeL_unique == 1 and bleu_unique == 1:
                fig.add_trace(go.Scatter(
                    x=list(range(len(history_df))),
                    y=history_df['rouge1'],
                    name=f'ROUGE-1/L & BLEU (Score: {history_df["rouge1"].iloc[0]:.3f})',
                    line=dict(color='#ff6b6b', width=4),
                    mode='lines+markers',
                    marker=dict(size=8)
                ))
                
                fig.add_annotation(
                    x=len(history_df)//2,
                    y=history_df['rouge1'].iloc[0] + 0.05,
                    text="üìå Scores identiques<br>(r√©ponses v√©rifi√©es)",
                    showarrow=True,
                    arrowhead=2,
                    bgcolor="rgba(255,255,255,0.8)",
                    bordercolor="#ff6b6b"
                )
            else:
                fig.add_trace(go.Scatter(
                    x=list(range(len(history_df))),
                    y=history_df['rouge1'],
                    name='ROUGE-1',
                    line=dict(color='#ff6b6b')
                ))
                
                fig.add_trace(go.Scatter(
                    x=list(range(len(history_df))),
                    y=history_df['rougeL'],
                    name='ROUGE-L',
                    line=dict(color='#4ecdc4')
                ))
                
                fig.add_trace(go.Scatter(
                    x=list(range(len(history_df))),
                    y=history_df['bleu'],
                    name='BLEU',
                    line=dict(color='#45b7d1')
                ))
            
            fig.update_layout(
                title="√âvolution des M√©triques NLP",
                xaxis_title="Questions",
                yaxis_title="Score",
                height=400,
                yaxis=dict(range=[0, 1.1])
            )
            
            st.plotly_chart(fig, use_container_width=True, key="enhanced_quality_metrics_chart")
        
        with col2:
            st.markdown("## üõ°Ô∏è Qualit√© & Fid√©lit√© Enrichies")
            
            fig2 = go.Figure()
            
            fig2.add_trace(go.Scatter(
                x=list(range(len(history_df))),
                y=history_df['relevance'],
                fill='tonexty',
                name='Pertinence',
                line=dict(color='#2ecc71')
            ))
            
            fig2.add_trace(go.Scatter(
                x=list(range(len(history_df))),
                y=history_df['faithfulness'],
                fill='tozeroy',
                name='Fid√©lit√©',
                line=dict(color='#f39c12')
            ))
            
            fig2.update_layout(
                title="Fid√©lit√© et Pertinence",
                xaxis_title="Questions",
                yaxis_title="Score",
                height=400
            )
            
            st.plotly_chart(fig2, use_container_width=True, key="enhanced_faithfulness_relevancy_chart")
    
    st.markdown("## üìã Historique d√©taill√©")
    
    if st.session_state.metrics_history:
        detailed_df = pd.DataFrame([
            {
                "Heure": m['timestamp'].strftime('%H:%M:%S'),
                "Question": m['question'][:50] + "..." if len(m['question']) > 50 else m['question'],
                "ROUGE-1": f"{m['rouge1']:.3f}",
                "ROUGE-L": f"{m['rougeL']:.3f}",
                "BLEU": f"{m['bleu']:.3f}",
                "Sim. S√©mantique": f"{m['similarity']:.3f}",
                "Fid√©lit√©": f"{m['faithfulness']:.3f}",
                "Pertinence": f"{m['relevance']:.3f}",
                "Temps (s)": f"{m['response_time']:.2f}"
            }
            for m in st.session_state.metrics_history
        ])
        
        st.dataframe(detailed_df, use_container_width=True)
    
    st.markdown("## üìä Statistiques Globales Enrichies")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("### üéØ Scores moyens")
        metrics_df = pd.DataFrame(st.session_state.metrics_history)
        numeric_columns = ['rouge1', 'rougeL', 'bleu', 'similarity', 'faithfulness', 'relevance', 'response_time']
        existing_numeric_cols = [col for col in numeric_columns if col in metrics_df.columns]
        
        if existing_numeric_cols:
            avg_metrics = metrics_df[existing_numeric_cols].mean()
            std_metrics = metrics_df[existing_numeric_cols].std()
            
            st.write(f"**ROUGE-1:** {avg_metrics.get('rouge1', 0):.3f} ¬± {std_metrics.get('rouge1', 0):.3f}")
            st.write(f"**ROUGE-L:** {avg_metrics.get('rougeL', 0):.3f} ¬± {std_metrics.get('rougeL', 0):.3f}")
            st.write(f"**BLEU:** {avg_metrics.get('bleu', 0):.3f} ¬± {std_metrics.get('bleu', 0):.3f}")
        else:
            st.write("Aucune m√©trique num√©rique disponible")
    
    with col2:
        st.markdown("### üß† Qualit√© S√©mantique")
        if existing_numeric_cols:
            st.write(f"**Similitude:** {avg_metrics.get('similarity', 0):.3f} ¬± {std_metrics.get('similarity', 0):.3f}")
            st.write(f"**Fid√©lit√©:** {avg_metrics.get('faithfulness', 0):.3f} ¬± {std_metrics.get('faithfulness', 0):.3f}")
            st.write(f"**Pertinence:** {avg_metrics.get('relevance', 0):.3f} ¬± {std_metrics.get('relevance', 0):.3f}")
        else:
            st.write("M√©triques s√©mantiques non disponibles")
    
    with col3:
        st.markdown("### ‚ö° Performance")
        if 'response_time' in metrics_df.columns:
            response_times = metrics_df['response_time'].tolist()
            st.write(f"**Temps moyen:** {np.mean(response_times):.2f}s")
            st.write(f"**Temps min/max:** {min(response_times):.2f}s / {max(response_times):.2f}s")
        else:
            st.write("**Temps moyen:** Non disponible")
        st.write(f"**Questions trait√©es:** {len(st.session_state.metrics_history)}")

def show_documentation_sources():
    col1, col2 = st.columns([3, 1])
    
    with col1:
        st.header("üîç Sources Documentaires Locales")
    
    with col2:
        if st.button("‚Üê Retour au Chat", type="primary", use_container_width=True):
            st.session_state.current_page = "chat"
            st.rerun()
    
    st.markdown("""
    ## üìö Corpus Documentaire DEMARIS Local
    
    ### üìÅ **Vos Documents de Formation**
    
    #### Documents training_corpus/ (Structure Simple)
    - üìÑ **basel_ii_operational.pdf** - R√©glementation Basel II sur le risque op√©rationnel
    - üîß **coso_framework.pdf** - Framework de contr√¥le interne COSO  
    - ü§ñ **demaris_methodolo.pdf** - M√©thodologie DEMARIS sp√©cifique
    
    ‚úÖ **Mode Local Activ√©** : Utilisation exclusive de vos documents
    
    ### üìä **Couverture Documentaire**
    """)
    
    training_corpus_dir = Path("training_corpus")
    if training_corpus_dir.exists():
        pdf_files = list(training_corpus_dir.glob("*.pdf"))
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            basel_files = [f for f in pdf_files if "basel" in f.name.lower() or "bale" in f.name.lower()]
            st.metric("üìÑ Basel Documents", len(basel_files))
        
        with col2:
            coso_files = [f for f in pdf_files if "coso" in f.name.lower()]
            st.metric("üîß COSO Framework", len(coso_files))
        
        with col3:
            demaris_files = [f for f in pdf_files if "demaris" in f.name.lower()]
            st.metric("ü§ñ DEMARIS Docs", len(demaris_files))
        
        st.markdown("### üìã Vos Documents de Formation")
        
        if pdf_files:
            files_data = []
            for pdf_file in pdf_files:
                size = pdf_file.stat().st_size
                modified = datetime.fromtimestamp(pdf_file.stat().st_mtime)
                
                filename_lower = pdf_file.name.lower()
                if "basel" in filename_lower or "bale" in filename_lower:
                    doc_type = "üìÑ Basel II Operational"
                elif "coso" in filename_lower:
                    doc_type = "üîß COSO Framework"
                elif "demaris" in filename_lower:
                    doc_type = "ü§ñ DEMARIS Methodology"
                else:
                    doc_type = "üìö Document Formation"
                
                files_data.append({
                    "Fichier": pdf_file.name,
                    "Type": doc_type,
                    "Taille": f"{size / (1024*1024):.1f} MB",
                    "Derni√®re MAJ": modified.strftime("%d/%m/%Y %H:%M")
                })
            
            files_df = pd.DataFrame(files_data)
            st.dataframe(files_df, use_container_width=True)
            
            st.markdown("### üìñ Contenu de Formation")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                if any("basel" in f.name.lower() or "bale" in f.name.lower() for f in pdf_files):
                    st.info("""
                    **üìÑ Basel II Operational**
                    - Risque op√©rationnel
                    - Approches de mesure
                    - Cadre r√©glementaire
                    """)
            
            with col2:
                if any("coso" in f.name.lower() for f in pdf_files):
                    st.info("""
                    **üîß COSO Framework**
                    - Contr√¥le interne
                    - 5 composants COSO
                    - Gestion des risques
                    """)
            
            with col3:
                if any("demaris" in f.name.lower() for f in pdf_files):
                    st.info("""
                    **ü§ñ DEMARIS Methodology**
                    - M√©thodologie d'analyse
                    - Processus d'√©valuation
                    - Framework sp√©cifique
                    """)
        else:
            st.warning("üìÅ Aucun fichier PDF trouv√© dans training_corpus/")
            st.info("""
            üí° **Placez vos documents directement dans :**
            training_corpus/basel_ii_operational.pdf
            training_corpus/coso_framework.pdf  
            training_corpus/demaris_methodolo.pdf
            """)
    
    else:
        st.error("üìÇ Dossier training_corpus non trouv√©!")
        st.info("""
        üîß **Cr√©ez le dossier et placez vos documents :**
        ```
        training_corpus/
        ‚îú‚îÄ‚îÄ basel_ii_operational.pdf
        ‚îú‚îÄ‚îÄ coso_framework.pdf
        ‚îî‚îÄ‚îÄ demaris_methodolo.pdf
        ```
        """)
    
    st.markdown("""
    ### ‚öôÔ∏è **Informations Techniques - Mode Local**
    
    **Architecture Locale :**
    - ‚úÖ Documents uniquement depuis training_corpus/
    - ‚úÖ Pas de t√©l√©chargement automatique
    - ‚úÖ Cache vectorstore local optimis√©
    - ‚úÖ Classification automatique par nom de fichier
    
    **Vos Documents :**
    - üìÑ **basel_ii_operational.pdf** ‚Üí R√©glementation Basel II
    - üîß **coso_framework.pdf** ‚Üí Framework de contr√¥le interne
    - ü§ñ **demaris_methodolo.pdf** ‚Üí M√©thodologie DEMARIS
    
    **Performance Locale :**
    - ‚ö° Retrieval optimis√© (8 documents locaux)
    - üîç Embeddings all-MiniLM-L6-v2 
    - ü§ñ LLM Qwen2.5 conservateur
    - üíæ Cache local persistant
    """)
    
    if st.button("üîÑ Recharger Documents Locaux"):
        with st.spinner("üìÅ Rechargement documents locaux..."):
            if 'enhanced_demaris_qa' in st.session_state:
                del st.session_state.enhanced_demaris_qa
            st.session_state.enhanced_demaris_qa = create_enhanced_demaris(force_reload=True)
        st.success("‚úÖ Documents locaux recharg√©s!")
        st.rerun()

if __name__ == "__main__":
    main()