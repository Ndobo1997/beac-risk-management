import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import lognorm, gamma, weibull_min, norm, expon, pareto, poisson
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import warnings
warnings.filterwarnings('ignore')
from datetime import datetime

# Configuration de la page
st.set_page_config(
    page_title="Analyse Exploratoire - Risque OpÃ©rationnel", 
    page_icon="ğŸ“Š", 
    layout="wide"
)

def formater_montant(montant, format_court=False):
    """Formate un montant en FCFA avec les unitÃ©s appropriÃ©es (k, M, Md)"""
    if pd.isna(montant) or montant == 0:
        return "0" if format_court else "0 FCFA"
    elif montant >= 1_000_000_000:
        return f"{montant/1_000_000_000:.1f} Md" if format_court else f"{montant/1_000_000_000:.1f} Md FCFA"
    elif montant >= 1_000_000:
        return f"{montant/1_000_000:.1f} M" if format_court else f"{montant/1_000_000:.1f} M FCFA"
    elif montant >= 1_000:
        return f"{montant/1_000:.1f} k" if format_court else f"{montant/1_000:.1f} k FCFA"
    else:
        return f"{montant:.0f}" if format_court else f"{montant:.0f} FCFA"

def analyse_exploratoire_complete():
    """
    Analyse exploratoire complÃ¨te des donnÃ©es de risque opÃ©rationnel
    AdaptÃ©e Ã  la structure exacte du fichier base_incidents.xlsx
    Avec affichage des vraies valeurs en FCFA
    """
    
    st.title("ğŸ“Š Analyse Exploratoire - Risque OpÃ©rationnel")
    st.markdown("---")
    st.write("*Analyse complÃ¨te des caractÃ©ristiques, tendances et distributions des incidents*")
    
    # =================== CHARGEMENT DES DONNÃ‰ES ===================
    
    @st.cache_data
    def charger_donnees():
        """Chargement et nettoyage des donnÃ©es avec conversion en FCFA rÃ©els"""
        try:
            # Chargement du fichier Excel avec la structure exacte
            df = pd.read_excel("data/base_incidents.xlsx", sheet_name="Incidents_DOF_augmente")
            
            st.info(f"ğŸ“ **Fichier chargÃ©** - Colonnes disponibles : {list(df.columns)}")
            
            # Colonnes principales identifiÃ©es
            cout_col = 'Cout_total_estime(en 10 000 FCFA)'
            entite_col = 'EntitÃ©'
            date_col = 'Date de survenance'
            categorie_col = 'CatÃ©gorie_Risque'
            gravite_col = 'GravitÃ©'
            
            # Nettoyage et CONVERSION DES COÃ›TS EN FCFA RÃ‰ELS
            cout_unite_10k = pd.to_numeric(df[cout_col], errors='coerce')
            cout_fcfa_reel = cout_unite_10k * 10_000  # Conversion en FCFA rÃ©els
            
            # Nettoyage des entitÃ©s
            entites = df[entite_col].astype(str)
            
            # Conversion des dates du format DD-MM-YYYY
            dates_str = df[date_col].astype(str)
            dates = pd.to_datetime(dates_str, format='%d-%m-%Y', errors='coerce')
            
            # Types/catÃ©gories de risque
            categories = df[categorie_col].astype(str)
            
            # GravitÃ©s
            gravites = df[gravite_col].astype(str)
            
            # Masque pour donnÃ©es valides
            mask = (
                (~pd.isna(cout_fcfa_reel)) & 
                (cout_fcfa_reel > 0) & 
                (~pd.isna(dates)) & 
                (entites != 'nan') & 
                (categories != 'nan')
            )
            
            # Construction du dataframe nettoyÃ© avec vraies valeurs FCFA
            df_clean = pd.DataFrame({
                'Severite': cout_fcfa_reel[mask],  # Maintenant en FCFA rÃ©els
                'Entite': entites[mask],
                'Date': dates[mask],
                'Categorie_Risque': categories[mask],
                'Gravite': gravites[mask],
                'Annee': dates[mask].dt.year,
                'Mois': dates[mask].dt.month,
                'Code': df['Code'][mask]
            })
            
            return {
                'df_original': df,
                'severites': cout_fcfa_reel[mask].values,  # En FCFA rÃ©els
                'entites': entites[mask].values,
                'dates': dates[mask],
                'categories': categories[mask].values,
                'gravites': gravites[mask].values,
                'df_clean': df_clean
            }
            
        except Exception as e:
            st.error(f"âŒ Erreur lors du chargement des donnÃ©es: {e}")
            st.info("ğŸ” VÃ©rifiez que le fichier 'base_incidents.xlsx' est prÃ©sent avec la feuille 'Incidents_DOF_augmente'")
            return None
    
    # Chargement des donnÃ©es
    data = charger_donnees()
    if data is None:
        st.stop()
    
    df = data['df_clean']
    severites = data['severites']
    entites = data['entites']
    dates = data['dates']
    categories = data['categories']
    gravites = data['gravites']
    
    # Informations gÃ©nÃ©rales
    st.success(f"âœ… **{len(severites):,} observations** chargÃ©es avec succÃ¨s sur **{len(data['df_original'])} incidents** totaux")
    
    # =================== 1. CARACTÃ‰RISTIQUES GÃ‰NÃ‰RALES ===================
    
    st.header("1ï¸âƒ£ CaractÃ©ristiques GÃ©nÃ©rales des DonnÃ©es")
    
    # Vue d'ensemble gÃ©nÃ©rale
    col1, col2, col3, col4, col5 = st.columns(5)
    
    periode_debut = df['Date'].min().strftime('%Y-%m-%d')
    periode_fin = df['Date'].max().strftime('%Y-%m-%d')
    nb_annees = (df['Date'].max() - df['Date'].min()).days / 365.25
    
    col1.metric("ğŸ“Š Total Incidents", f"{len(severites):,}")
    col2.metric("ğŸ¢ EntitÃ©s Uniques", f"{df['Entite'].nunique()}")
    col3.metric("ğŸ“… PÃ©riode Analyse", f"{nb_annees:.1f} ans")
    col4.metric("ğŸ’° Perte Totale", f"{np.sum(severites)/1_000_000_000:.1f}", delta="Milliards FCFA")
    col5.metric("ğŸ“ˆ FrÃ©quence Moyenne", f"{len(severites)/nb_annees:.1f}/an")
    
    st.info(f"**PÃ©riode d'analyse :** {periode_debut} â†’ {periode_fin}")
    st.caption("ğŸ’¡ **Note :** La perte totale est affichÃ©e en milliards de FCFA dans la mÃ©trique principale")
    
    # Vue des donnÃ©es brutes
    with st.expander("ğŸ” AperÃ§u des DonnÃ©es Brutes"):
        # CrÃ©ation d'un dataframe d'affichage avec formatage
        df_display_raw = df.copy()
        df_display_raw['Severite_Formatee'] = df_display_raw['Severite'].apply(formater_montant)
        
        # Colonnes Ã  afficher
        colonnes_display = ['Code', 'Entite', 'Date', 'Categorie_Risque', 'Gravite', 'Severite_Formatee']
        df_show = df_display_raw[colonnes_display].head(10)
        df_show = df_show.rename(columns={'Severite_Formatee': 'SÃ©vÃ©ritÃ©'})
        
        st.dataframe(df_show, use_container_width=True)
        
        col1, col2 = st.columns(2)
        with col1:
            st.write("**CatÃ©gories de Risque Uniques:**")
            st.write(df['Categorie_Risque'].value_counts())
        
        with col2:
            st.write("**Niveaux de GravitÃ© Uniques:**")
            st.write(df['Gravite'].value_counts())
    
    # =================== 2. CARACTÃ‰RISTIQUES PAR ENTITÃ‰ ===================
    
    st.subheader("ğŸ¢ Analyse DÃ©taillÃ©e par EntitÃ©")
    
    # Calcul des statistiques par entitÃ© avec formatage
    def calcul_stats_entites_avec_formatage(df):
        """Calcul des statistiques par entitÃ© avec formatage appropriÃ©"""
        try:
            stats_list = []
            for entite in df['Entite'].unique():
                subset = df[df['Entite'] == entite]
                severites_entite = subset['Severite'].values  # DÃ©jÃ  en FCFA rÃ©els
                
                if len(severites_entite) > 0:
                    # CatÃ©gorie et gravitÃ© principales
                    cat_principale = subset['Categorie_Risque'].mode().iloc[0] if len(subset['Categorie_Risque'].mode()) > 0 else 'N/A'
                    grav_principale = subset['Gravite'].mode().iloc[0] if len(subset['Gravite'].mode()) > 0 else 'N/A'
                    
                    stats_entite = {
                        'Entite': entite,
                        'Nb_Incidents': len(severites_entite),
                        'Severite_Moyenne': np.mean(severites_entite),
                        'Severite_Mediane': np.median(severites_entite),
                        'Ecart_Type': np.std(severites_entite, ddof=1) if len(severites_entite) > 1 else 0,
                        'Severite_Min': np.min(severites_entite),
                        'Severite_Max': np.max(severites_entite),
                        'Perte_Totale': np.sum(severites_entite),
                        'Premiere_Date': subset['Date'].min(),
                        'Derniere_Date': subset['Date'].max(),
                        'Categorie_Principale': cat_principale,
                        'Gravite_Principale': grav_principale
                    }
                    stats_list.append(stats_entite)
            
            return pd.DataFrame(stats_list).set_index('Entite')
            
        except Exception as e:
            st.error(f"Erreur dans calcul_stats_entites_avec_formatage : {e}")
            return None
    
    stats_entites = calcul_stats_entites_avec_formatage(df)
    
    if stats_entites is not None:
        # Ajout de mÃ©triques dÃ©rivÃ©es
        total_incidents = len(df)
        total_pertes = df['Severite'].sum()
        
        stats_entites['Part_Incidents_%'] = (stats_entites['Nb_Incidents'] / total_incidents * 100).round(1)
        stats_entites['Part_Pertes_%'] = (stats_entites['Perte_Totale'] / total_pertes * 100).round(1)
        stats_entites['Frequence_Annuelle'] = (stats_entites['Nb_Incidents'] / nb_annees).round(1)
        
        # CV sÃ©curisÃ©
        cv_values = []
        for _, row in stats_entites.iterrows():
            if row['Severite_Moyenne'] > 0:
                cv = (row['Ecart_Type'] / row['Severite_Moyenne'])
            else:
                cv = 0
            cv_values.append(cv)
        
        stats_entites['CV_Severite'] = np.array(cv_values).round(2)
        
        # Nettoyage des noms d'entitÃ©s pour l'affichage
        stats_entites['Entite_Court'] = [nom.replace('DGEFRI-DOF : ', '') for nom in stats_entites.index]
        
        # Ajout des colonnes formatÃ©es
        stats_entites['Severite_Moyenne_Format'] = stats_entites['Severite_Moyenne'].apply(formater_montant)
        stats_entites['Severite_Mediane_Format'] = stats_entites['Severite_Mediane'].apply(formater_montant)
        stats_entites['Severite_Max_Format'] = stats_entites['Severite_Max'].apply(formater_montant)
        stats_entites['Perte_Totale_Format'] = stats_entites['Perte_Totale'].apply(formater_montant)
        
        # Tri par nombre d'incidents
        stats_entites = stats_entites.sort_values('Nb_Incidents', ascending=False)
        
        # VÃ©rification de cohÃ©rence des montants
        total_calcule = np.sum(severites)
        total_par_entites = stats_entites['Perte_Totale'].sum()
        difference = abs(total_calcule - total_par_entites)
        
        if difference < 0.01:  # TolÃ©rance pour les erreurs d'arrondi
            st.success(f"âœ… **VÃ©rification cohÃ©rence :** Total gÃ©nÃ©ral = Somme par entitÃ©s = {formater_montant(total_calcule)}")
        else:
            st.warning(f"âš ï¸ **IncohÃ©rence dÃ©tectÃ©e :** Total gÃ©nÃ©ral ({formater_montant(total_calcule)}) â‰  Somme entitÃ©s ({formater_montant(total_par_entites)})")
    else:
        st.error("âŒ Impossible de calculer les statistiques par entitÃ©")
    
    # Affichage du tableau avec formatage
    if stats_entites is not None:
        colonnes_affichage = [
            'Entite_Court', 'Nb_Incidents', 'Frequence_Annuelle', 
            'Severite_Moyenne_Format', 'Severite_Mediane_Format', 'Severite_Max_Format',
            'Part_Incidents_%', 'Part_Pertes_%', 'CV_Severite',
            'Categorie_Principale', 'Gravite_Principale'
        ]
    
        df_display = stats_entites[colonnes_affichage].copy()
        df_display = df_display.rename(columns={
            'Entite_Court': 'EntitÃ©',
            'Severite_Moyenne_Format': 'SÃ©vÃ©ritÃ© Moyenne',
            'Severite_Mediane_Format': 'SÃ©vÃ©ritÃ© MÃ©diane',
            'Severite_Max_Format': 'SÃ©vÃ©ritÃ© Max',
            'Part_Incidents_%': 'Part Incidents (%)',
            'Part_Pertes_%': 'Part Pertes (%)'
        })
        
        st.dataframe(
            df_display.style.format({
                'Part Incidents (%)': '{:.1f}%',
                'Part Pertes (%)': '{:.1f}%',
                'Frequence_Annuelle': '{:.1f}',
                'CV_Severite': '{:.2f}'
            }),
            use_container_width=True
        )
    
        # Graphiques par entitÃ©
        col1, col2 = st.columns(2)
        
        with col1:
            # Top 10 entitÃ©s par nombre d'incidents
            top_entites = stats_entites.head(10)
            entites_courtes = [nom[:25] + '...' if len(nom) > 25 else nom for nom in top_entites['Entite_Court']]
            
            fig, ax = plt.subplots(figsize=(10, 6))
            ax.bar(range(len(entites_courtes)), top_entites['Nb_Incidents'])
            ax.set_xticks(range(len(entites_courtes)))
            ax.set_xticklabels(entites_courtes, rotation=45, ha='right')
            ax.set_title("Top 10 - Nombre d'Incidents par EntitÃ©")
            ax.set_ylabel("Nombre d'Incidents")
            plt.tight_layout()
            st.pyplot(fig)
            plt.close(fig)
        
        with col2:
            # Top 10 entitÃ©s par pertes totales
            fig, ax = plt.subplots(figsize=(10, 6))
            pertes_millions = top_entites['Perte_Totale'] / 1_000_000  # Conversion en millions pour l'affichage
            ax.bar(range(len(entites_courtes)), pertes_millions)
            ax.set_xticks(range(len(entites_courtes)))
            ax.set_xticklabels(entites_courtes, rotation=45, ha='right')
            ax.set_title("Top 10 - Pertes Totales par EntitÃ©")
            ax.set_ylabel("Pertes Totales (Millions FCFA)")
            plt.tight_layout()
            st.pyplot(fig)
            plt.close(fig)
    else:
        st.warning("âš ï¸ Impossible d'afficher les graphiques par entitÃ©")
    
    # =================== 4. DISTRIBUTION PAR CATÃ‰GORIE DE RISQUE ===================
    
    st.header("2ï¸âƒ£ Distribution des Incidents par CatÃ©gorie de Risque")
    
    st.subheader("ğŸ“‹ Analyse par CatÃ©gorie de Risque")
    
    # Calcul des statistiques par catÃ©gorie avec formatage
    def calcul_stats_categories_avec_formatage(df):
        """Calcul des statistiques par catÃ©gorie avec formatage appropriÃ©"""
        try:
            stats_list = []
            for categorie in df['Categorie_Risque'].unique():
                subset = df[df['Categorie_Risque'] == categorie]
                severites_cat = subset['Severite'].values  # DÃ©jÃ  en FCFA rÃ©els
                
                if len(severites_cat) > 0:
                    stats_cat = {
                        'Categorie': categorie,
                        'Nb_Incidents': len(severites_cat),
                        'Severite_Moyenne': np.mean(severites_cat),
                        'Severite_Mediane': np.median(severites_cat),
                        'Perte_Totale': np.sum(severites_cat),
                        'Ecart_Type': np.std(severites_cat, ddof=1) if len(severites_cat) > 1 else 0,
                        'Nb_Entites': len(subset['Entite'].unique())
                    }
                    stats_list.append(stats_cat)
            
            df_stats = pd.DataFrame(stats_list).set_index('Categorie')
            
            # Calculs dÃ©rivÃ©s
            total_incidents = len(df)
            total_pertes = df['Severite'].sum()
            df_stats['Part_Incidents_%'] = (df_stats['Nb_Incidents'] / total_incidents * 100).round(1)
            df_stats['Part_Pertes_%'] = (df_stats['Perte_Totale'] / total_pertes * 100).round(1)
            
            # Ajout des colonnes formatÃ©es
            df_stats['Severite_Moyenne_Format'] = df_stats['Severite_Moyenne'].apply(formater_montant)
            df_stats['Severite_Mediane_Format'] = df_stats['Severite_Mediane'].apply(formater_montant)
            df_stats['Perte_Totale_Format'] = df_stats['Perte_Totale'].apply(formater_montant)
            
            return df_stats.sort_values('Nb_Incidents', ascending=False)
            
        except Exception as e:
            st.error(f"Erreur dans calcul_stats_categories_avec_formatage : {e}")
            return None
    
    stats_categories = calcul_stats_categories_avec_formatage(df)
    
    # DÃ©finition des noms complets des catÃ©gories
    if stats_categories is not None:
        categories_noms = {
            'RF': 'Risques de Fraude',
            'RSI': 'Risques SystÃ¨mes d\'Information',
            'RH': 'Risques Humains',
            'RC': 'Risques de CrÃ©dit',
            'RO': 'Risques OpÃ©rationnels',
            'RM': 'Risques de MarchÃ©'
        }
        
        stats_categories['Nom_Complet'] = [categories_noms.get(cat, cat) for cat in stats_categories.index]
    
    # Affichage avec formatage
    colonnes_cat_display = ['Nom_Complet', 'Nb_Incidents', 'Severite_Moyenne_Format', 'Severite_Mediane_Format', 
                           'Perte_Totale_Format', 'Part_Incidents_%', 'Part_Pertes_%', 'Nb_Entites']
    
    df_cat_display = stats_categories[colonnes_cat_display].copy()
    df_cat_display = df_cat_display.rename(columns={
        'Nom_Complet': 'CatÃ©gorie',
        'Severite_Moyenne_Format': 'SÃ©vÃ©ritÃ© Moyenne',
        'Severite_Mediane_Format': 'SÃ©vÃ©ritÃ© MÃ©diane',
        'Perte_Totale_Format': 'Perte Totale',
        'Part_Incidents_%': 'Part Incidents (%)',
        'Part_Pertes_%': 'Part Pertes (%)',
        'Nb_Entites': 'Nb EntitÃ©s'
    })
    
    st.dataframe(
        df_cat_display.style.format({
            'Part Incidents (%)': '{:.1f}%',
            'Part Pertes (%)': '{:.1f}%'
        }),
        use_container_width=True
    )
    
    # Graphiques par catÃ©gorie
    if stats_categories is not None and len(stats_categories) > 0:
        col1, col2 = st.columns(2)
        
        with col1:
            # RÃ©partition des incidents par catÃ©gorie
            fig, ax = plt.subplots(figsize=(8, 6))
            ax.pie(stats_categories['Nb_Incidents'], labels=stats_categories['Nom_Complet'], autopct='%1.1f%%')
            ax.set_title("RÃ©partition des Incidents par CatÃ©gorie de Risque")
            st.pyplot(fig)
            plt.close(fig)
        
        with col2:
            # SÃ©vÃ©ritÃ© moyenne par catÃ©gorie
            fig, ax = plt.subplots(figsize=(8, 6))
            severites_millions = stats_categories['Severite_Moyenne'] / 1_000_000
            ax.bar(range(len(stats_categories)), severites_millions)
            ax.set_xticks(range(len(stats_categories)))
            ax.set_xticklabels(stats_categories['Nom_Complet'], rotation=45, ha='right')
            ax.set_title("SÃ©vÃ©ritÃ© Moyenne par CatÃ©gorie de Risque")
            ax.set_ylabel("SÃ©vÃ©ritÃ© Moyenne (Millions FCFA)")
            plt.tight_layout()
            st.pyplot(fig)
            plt.close(fig)
    else:
        st.warning("âš ï¸ Impossible d'afficher les graphiques par catÃ©gorie")
    
    # =================== 5. ANALYSE PAR GRAVITÃ‰ ===================
    
    st.subheader("âš¡ Analyse par Niveau de GravitÃ©")
    
    # Calcul des statistiques par gravitÃ© avec formatage
    def calcul_stats_gravites_avec_formatage(df):
        """Calcul des statistiques par gravitÃ© avec formatage appropriÃ©"""
        try:
            stats_list = []
            for gravite in df['Gravite'].unique():
                if pd.isna(gravite) or gravite == 'nan':
                    continue
                    
                subset = df[df['Gravite'] == gravite]
                severites_grav = subset['Severite'].values  # DÃ©jÃ  en FCFA rÃ©els
                
                if len(severites_grav) > 0:
                    stats_grav = {
                        'Gravite': gravite,
                        'Nb_Incidents': len(severites_grav),
                        'Severite_Moyenne': np.mean(severites_grav),
                        'Severite_Mediane': np.median(severites_grav),
                        'Perte_Totale': np.sum(severites_grav),
                        'Nb_Entites': len(subset['Entite'].unique())
                    }
                    stats_list.append(stats_grav)
            
            df_stats = pd.DataFrame(stats_list).set_index('Gravite')
            
            # Calculs dÃ©rivÃ©s
            total_incidents = len(df)
            total_pertes = df['Severite'].sum()
            df_stats['Part_Incidents_%'] = (df_stats['Nb_Incidents'] / total_incidents * 100).round(1)
            df_stats['Part_Pertes_%'] = (df_stats['Perte_Totale'] / total_pertes * 100).round(1)
            
            # Ajout des colonnes formatÃ©es
            df_stats['Severite_Moyenne_Format'] = df_stats['Severite_Moyenne'].apply(formater_montant)
            df_stats['Severite_Mediane_Format'] = df_stats['Severite_Mediane'].apply(formater_montant)
            df_stats['Perte_Totale_Format'] = df_stats['Perte_Totale'].apply(formater_montant)
            
            # Ordre logique des gravitÃ©s
            ordre_gravite = ['TrÃ¨s faible', 'Faible', 'Moyen', 'Fort', 'TrÃ¨s fort']
            gravites_presentes = [g for g in ordre_gravite if g in df_stats.index]
            
            return df_stats.reindex(gravites_presentes)
            
        except Exception as e:
            st.error(f"Erreur dans calcul_stats_gravites_avec_formatage : {e}")
            return None
    
    stats_gravites = calcul_stats_gravites_avec_formatage(df)
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        if stats_gravites is not None and len(stats_gravites) > 0:
            # Affichage avec formatage
            colonnes_grav_display = ['Nb_Incidents', 'Severite_Moyenne_Format', 'Severite_Mediane_Format',
                                   'Perte_Totale_Format', 'Part_Incidents_%', 'Part_Pertes_%', 'Nb_Entites']
            
            df_grav_display = stats_gravites[colonnes_grav_display].copy()
            df_grav_display = df_grav_display.rename(columns={
                'Severite_Moyenne_Format': 'SÃ©vÃ©ritÃ© Moyenne',
                'Severite_Mediane_Format': 'SÃ©vÃ©ritÃ© MÃ©diane',
                'Perte_Totale_Format': 'Perte Totale',
                'Part_Incidents_%': 'Part Incidents (%)',
                'Part_Pertes_%': 'Part Pertes (%)',
                'Nb_Entites': 'Nb EntitÃ©s'
            })
            
            st.dataframe(
                df_grav_display.style.format({
                    'Part Incidents (%)': '{:.1f}%',
                    'Part Pertes (%)': '{:.1f}%'
                }),
                use_container_width=True
            )
        else:
            st.error("âŒ Impossible de calculer les statistiques par gravitÃ©")
    
    with col2:
        if stats_gravites is not None and len(stats_gravites) > 0:
            # Graphique gravitÃ© vs sÃ©vÃ©ritÃ©
            fig, ax = plt.subplots(figsize=(8, 6))
            severites_millions = stats_gravites['Severite_Moyenne'] / 1_000_000
            scatter = ax.scatter(range(len(stats_gravites.index)), severites_millions, 
                               s=stats_gravites['Nb_Incidents']*10, alpha=0.6)
            ax.set_xticks(range(len(stats_gravites.index)))
            ax.set_xticklabels(stats_gravites.index, rotation=45)
            ax.set_title("GravitÃ© vs SÃ©vÃ©ritÃ© Moyenne")
            ax.set_xlabel("Niveau de GravitÃ©")
            ax.set_ylabel("SÃ©vÃ©ritÃ© Moyenne (Millions FCFA)")
            ax.grid(True, alpha=0.3)
            plt.tight_layout()
            st.pyplot(fig)
            plt.close(fig)
        else:
            st.warning("âš ï¸ Impossible d'afficher le graphique par gravitÃ©")
    
    # =================== 6. MATRICE DE CORRÃ‰LATION ===================
    
    st.subheader("ğŸ”— Matrice CatÃ©gorie Ã— EntitÃ©")
    
    # Heatmap des incidents par catÃ©gorie et entitÃ© (top 10 entitÃ©s)
    if stats_entites is not None and len(stats_entites) > 0:
        top_10_entites = stats_entites.head(10).index.tolist()
        df_top = df[df['Entite'].isin(top_10_entites)]
        
        # Noms courts pour l'affichage
        df_top_display = df_top.copy()
        df_top_display['Entite_Court'] = [nom.replace('DGEFRI-DOF : ', '') for nom in df_top_display['Entite']]
        
        try:
            matrice_cat_entite = pd.crosstab(df_top_display['Categorie_Risque'], df_top_display['Entite_Court'])
            
            # Heatmap avec seaborn
            fig, ax = plt.subplots(figsize=(12, 6))
            sns.heatmap(matrice_cat_entite, annot=True, fmt='d', cmap='YlOrRd', ax=ax)
            ax.set_title("Heatmap Incidents: CatÃ©gorie Ã— EntitÃ© (Top 10)")
            ax.set_xlabel("EntitÃ©")
            ax.set_ylabel("CatÃ©gorie de Risque")
            plt.tight_layout()
            st.pyplot(fig)
            plt.close(fig)
        except Exception as e:
            st.warning(f"âš ï¸ Impossible d'afficher la heatmap: {e}")
    else:
        st.warning("âš ï¸ Impossible d'afficher la matrice de corrÃ©lation")
    
    # =================== 7. ANALYSE DES TENDANCES TEMPORELLES ===================
    
    st.header("3ï¸âƒ£ Analyse des Tendances Temporelles")
    
    # Ã‰volution annuelle
    st.subheader("ğŸ“… Ã‰volution Annuelle")
    
    # Calcul des tendances annuelles avec formatage
    def calcul_trends_annuelles_avec_formatage(df):
        """Calcul des tendances annuelles avec formatage appropriÃ©"""
        try:
            trends_list = []
            for annee in sorted(df['Annee'].unique()):
                subset = df[df['Annee'] == annee]
                severites_annee = subset['Severite'].values  # DÃ©jÃ  en FCFA rÃ©els
                
                if len(severites_annee) > 0:
                    trend_annee = {
                        'Annee': annee,
                        'Nb_Incidents': len(severites_annee),
                        'Pertes_Totales': np.sum(severites_annee),
                        'Severite_Moyenne': np.mean(severites_annee),
                        'Severite_Mediane': np.median(severites_annee)
                    }
                    trends_list.append(trend_annee)
            
            df_trends = pd.DataFrame(trends_list).set_index('Annee')
            
            # Ajout des colonnes formatÃ©es
            df_trends['Pertes_Totales_Format'] = df_trends['Pertes_Totales'].apply(formater_montant)
            df_trends['Severite_Moyenne_Format'] = df_trends['Severite_Moyenne'].apply(formater_montant)
            df_trends['Severite_Mediane_Format'] = df_trends['Severite_Mediane'].apply(formater_montant)
            
            return df_trends
            
        except Exception as e:
            st.error(f"Erreur dans calcul_trends_annuelles_avec_formatage : {e}")
            return None
    
    trends_annuelles = calcul_trends_annuelles_avec_formatage(df)
    
    # Graphiques temporels
    if trends_annuelles is not None and len(trends_annuelles) > 0:
        col1, col2 = st.columns(2)
        
        with col1:
            # Ã‰volution du nombre d'incidents
            fig, ax = plt.subplots(figsize=(10, 6))
            ax.plot(trends_annuelles.index, trends_annuelles['Nb_Incidents'], marker='o')
            ax.set_title("Ã‰volution du Nombre d'Incidents par AnnÃ©e")
            ax.set_xlabel("AnnÃ©e")
            ax.set_ylabel("Nombre d'Incidents")
            ax.grid(True, alpha=0.3)
            plt.tight_layout()
            st.pyplot(fig)
            plt.close(fig)
        
        with col2:
            # Ã‰volution des pertes totales
            fig, ax = plt.subplots(figsize=(10, 6))
            pertes_millions = trends_annuelles['Pertes_Totales'] / 1_000_000
            ax.plot(trends_annuelles.index, pertes_millions, marker='o', color='red')
            ax.set_title("Ã‰volution des Pertes Totales par AnnÃ©e")
            ax.set_xlabel("AnnÃ©e")
            ax.set_ylabel("Pertes Totales (Millions FCFA)")
            ax.grid(True, alpha=0.3)
            plt.tight_layout()
            st.pyplot(fig)
            plt.close(fig)
    else:
        st.warning("âš ï¸ Impossible d'afficher les tendances annuelles")
    
    # Analyse mensuelle (saisonnalitÃ©)
    st.subheader("ğŸŒ“ Analyse de SaisonnalitÃ©")
    
    # Calcul des tendances mensuelles avec formatage
    def calcul_trends_mensuelles_avec_formatage(df):
        """Calcul des tendances mensuelles avec formatage appropriÃ©"""
        try:
            trends_list = []
            for mois in range(1, 13):
                subset = df[df['Mois'] == mois]
                severites_mois = subset['Severite'].values  # DÃ©jÃ  en FCFA rÃ©els
                
                if len(severites_mois) > 0:
                    # Moyenne des incidents par mois sur toutes les annÃ©es
                    nb_annees_mois = len(subset['Annee'].unique())
                    nb_incidents_moyen = len(severites_mois) / nb_annees_mois if nb_annees_mois > 0 else 0
                    
                    trend_mois = {
                        'Mois': mois,
                        'Nb_Incidents_Moyen': nb_incidents_moyen,
                        'Severite_Moyenne': np.mean(severites_mois)
                    }
                else:
                    trend_mois = {
                        'Mois': mois,
                        'Nb_Incidents_Moyen': 0,
                        'Severite_Moyenne': 0
                    }
                trends_list.append(trend_mois)
            
            return pd.DataFrame(trends_list).set_index('Mois')
            
        except Exception as e:
            st.error(f"Erreur dans calcul_trends_mensuelles_avec_formatage : {e}")
            return None
    
    trends_mensuelles = calcul_trends_mensuelles_avec_formatage(df)
    
    # Graphique saisonnalitÃ©
    if trends_mensuelles is not None and len(trends_mensuelles) > 0:
        mois_noms = ['Jan', 'FÃ©v', 'Mar', 'Avr', 'Mai', 'Juin', 
                    'Juil', 'AoÃ»t', 'Sep', 'Oct', 'Nov', 'DÃ©c']
        
        fig, ax1 = plt.subplots(figsize=(12, 6))
        
        color = 'tab:blue'
        ax1.set_xlabel('Mois')
        ax1.set_ylabel('Nb Incidents Moyens', color=color)
        ax1.plot(mois_noms, trends_mensuelles['Nb_Incidents_Moyen'], color=color, marker='o', label='Incidents Moyens')
        ax1.tick_params(axis='y', labelcolor=color)
        ax1.set_title("SaisonnalitÃ© des Incidents et SÃ©vÃ©ritÃ©s")
        
        ax2 = ax1.twinx()
        color = 'tab:red'
        ax2.set_ylabel('SÃ©vÃ©ritÃ© Moyenne (Millions FCFA)', color=color)
        severites_moy_millions = trends_mensuelles['Severite_Moyenne'] / 1_000_000
        ax2.plot(mois_noms, severites_moy_millions, color=color, marker='s', label='SÃ©vÃ©ritÃ© Moyenne')
        ax2.tick_params(axis='y', labelcolor=color)
        
        plt.tight_layout()
        st.pyplot(fig)
        plt.close(fig)
    else:
        st.warning("âš ï¸ Impossible d'afficher l'analyse de saisonnalitÃ©")
    
    # Tests de tendance
    if trends_annuelles is not None and len(trends_annuelles) > 0:
        st.subheader("ğŸ“ˆ Tests Statistiques de Tendance")
        
        # Test de Mann-Kendall pour tendance
        from scipy.stats import kendalltau
        
        try:
            annees = trends_annuelles.index.values
            incidents = trends_annuelles['Nb_Incidents'].values
            pertes = trends_annuelles['Pertes_Totales'].values
            
            tau_incidents, p_incidents = kendalltau(annees, incidents)
            tau_pertes, p_pertes = kendalltau(annees, pertes)
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric(
                    "Tendance Incidents",
                    f"Ï„ = {tau_incidents:.3f}",
                    f"p = {p_incidents:.3f} {'ğŸ“ˆ' if tau_incidents > 0 else 'ğŸ“‰' if tau_incidents < 0 else 'â¡ï¸'}"
                )
            
            with col2:
                st.metric(
                    "Tendance Pertes",
                    f"Ï„ = {tau_pertes:.3f}",
                    f"p = {p_pertes:.3f} {'ğŸ“ˆ' if tau_pertes > 0 else 'ğŸ“‰' if tau_pertes < 0 else 'â¡ï¸'}"
                )
            
            # InterprÃ©tation
            interpretation_incidents = "Tendance croissante significative" if p_incidents < 0.05 and tau_incidents > 0 else \
                                    "Tendance dÃ©croissante significative" if p_incidents < 0.05 and tau_incidents < 0 else \
                                    "Pas de tendance significative"
            
            interpretation_pertes = "Tendance croissante significative" if p_pertes < 0.05 and tau_pertes > 0 else \
                                  "Tendance dÃ©croissante significative" if p_pertes < 0.05 and tau_pertes < 0 else \
                                  "Pas de tendance significative"
            
            st.info(f"""
            **ğŸ” InterprÃ©tation des Tendances :**
            - **Incidents :** {interpretation_incidents}
            - **Pertes :** {interpretation_pertes}
            """)
        except Exception as e:
            st.warning(f"âš ï¸ Impossible de calculer les tests de tendance: {e}")
    else:
        st.warning("âš ï¸ Pas de donnÃ©es pour les tests de tendance")
    
    # =================== 8. STATISTIQUES DE SÃ‰VÃ‰RITÃ‰ AVANCÃ‰ES ===================
    
    st.header("4ï¸âƒ£ Statistiques de SÃ©vÃ©ritÃ© DÃ©taillÃ©es")
    
    # Statistiques descriptives complÃ¨tes
    st.subheader("ğŸ“Š Statistiques Descriptives ComplÃ¨tes")
    
    def calculer_stats_completes(data):
        """Calcul de toutes les statistiques descriptives"""
        try:
            # Conversion en array numpy pour Ã©viter les problÃ¨mes d'Index
            data_array = np.array(data).flatten()
            data_clean = data_array[~np.isnan(data_array)]
            
            if len(data_clean) == 0:
                return {'Erreur': 'Pas de donnÃ©es valides'}
            
            # Calcul du mode de faÃ§on sÃ©curisÃ©e
            try:
                mode_result = stats.mode(data_clean, keepdims=False)
                mode_val = float(mode_result.mode) if hasattr(mode_result, 'mode') else float(mode_result[0])
            except:
                mode_val = np.nan
            
            return {
                'Observations': int(len(data_clean)),
                'Moyenne': float(np.mean(data_clean)),
                'MÃ©diane': float(np.median(data_clean)),
                'Mode': mode_val,
                'Ã‰cart-Type': float(np.std(data_clean, ddof=1)),
                'Variance': float(np.var(data_clean, ddof=1)),
                'CV (%)': float((np.std(data_clean, ddof=1) / np.mean(data_clean)) * 100),
                'Minimum': float(np.min(data_clean)),
                'Q1 (25%)': float(np.percentile(data_clean, 25)),
                'Q3 (75%)': float(np.percentile(data_clean, 75)),
                'Maximum': float(np.max(data_clean)),
                'IQR': float(np.percentile(data_clean, 75) - np.percentile(data_clean, 25)),
                'Ã‰tendue': float(np.max(data_clean) - np.min(data_clean)),
                'AsymÃ©trie': float(stats.skew(data_clean)),
                'Aplatissement': float(stats.kurtosis(data_clean)),
                'Erreur_Standard': float(stats.sem(data_clean))
            }
        except Exception as e:
            st.error(f"Erreur dans le calcul des statistiques : {e}")
            return {'Erreur': str(e)}
    
    # Calcul pour toutes les donnÃ©es
    stats_globales = calculer_stats_completes(severites)
    
    # Affichage en colonnes avec formatage
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("**ğŸ¯ Tendance Centrale**")
        # Affichage intelligent selon la taille des montants
        moyenne_val = stats_globales['Moyenne']
        mediane_val = stats_globales['MÃ©diane'] 
        mode_val = stats_globales['Mode']
        
        if moyenne_val >= 1_000_000_000:
            st.metric("Moyenne", f"{moyenne_val/1_000_000_000:.2f}", delta="Milliards FCFA")
        else:
            st.metric("Moyenne", f"{moyenne_val/1_000_000:.1f}", delta="Millions FCFA")
            
        if mediane_val >= 1_000_000_000:
            st.metric("MÃ©diane", f"{mediane_val/1_000_000_000:.2f}", delta="Milliards FCFA")
        else:
            st.metric("MÃ©diane", f"{mediane_val/1_000_000:.1f}", delta="Millions FCFA")
            
        if mode_val >= 1_000_000_000:
            st.metric("Mode", f"{mode_val/1_000_000_000:.2f}", delta="Milliards FCFA")
        else:
            st.metric("Mode", f"{mode_val/1_000_000:.1f}", delta="Millions FCFA")
        
    with col2:
        st.markdown("**ğŸ“ Dispersion**")
        ecart_type_val = stats_globales['Ã‰cart-Type']
        iqr_val = stats_globales['IQR']
        erreur_std_val = stats_globales['Erreur_Standard']
        
        if ecart_type_val >= 1_000_000_000:
            st.metric("Ã‰cart-Type", f"{ecart_type_val/1_000_000_000:.2f}", delta="Milliards FCFA")
        else:
            st.metric("Ã‰cart-Type", f"{ecart_type_val/1_000_000:.1f}", delta="Millions FCFA")
            
        st.metric("CV (%)", f"{stats_globales['CV (%)']:,.1f}%")
        
        if iqr_val >= 1_000_000_000:
            st.metric("IQR", f"{iqr_val/1_000_000_000:.2f}", delta="Milliards FCFA")
        else:
            st.metric("IQR", f"{iqr_val/1_000_000:.1f}", delta="Millions FCFA")
        
    with col3:
        st.markdown("**ğŸ“ Forme**")
        st.metric("AsymÃ©trie", f"{stats_globales['AsymÃ©trie']:,.2f}")
        st.metric("Aplatissement", f"{stats_globales['Aplatissement']:,.2f}")
        
        if erreur_std_val >= 1_000_000_000:
            st.metric("Erreur Standard", f"{erreur_std_val/1_000_000_000:.2f}", delta="Milliards FCFA")
        else:
            st.metric("Erreur Standard", f"{erreur_std_val/1_000_000:.1f}", delta="Millions FCFA")
    
    # InterprÃ©tation des statistiques
    st.subheader("ğŸ” InterprÃ©tation des Statistiques")
    
    asymetrie = stats_globales['AsymÃ©trie']
    aplatissement = stats_globales['Aplatissement']
    cv = stats_globales['CV (%)']
    
    # Analyse de l'asymÃ©trie
    if asymetrie > 2:
        interp_asym = "TrÃ¨s fortement asymÃ©trique Ã  droite - Distribution trÃ¨s dÃ©formÃ©e"
    elif asymetrie > 1:
        interp_asym = "Fortement asymÃ©trique Ã  droite - Concentration sur faibles valeurs"
    elif asymetrie > 0.5:
        interp_asym = "ModÃ©rÃ©ment asymÃ©trique Ã  droite - LÃ©gÃ¨re concentration sur faibles valeurs"
    elif asymetrie > -0.5:
        interp_asym = "Quasi-symÃ©trique - Distribution Ã©quilibrÃ©e"
    else:
        interp_asym = "AsymÃ©trique Ã  gauche - Concentration sur fortes valeurs"
    
    # Analyse de l'aplatissement
    if aplatissement > 3:
        interp_aplat = "Queues trÃ¨s lourdes - Ã‰vÃ©nements extrÃªmes frÃ©quents"
    elif aplatissement > 0:
        interp_aplat = "Queues lourdes - Plus d'Ã©vÃ©nements extrÃªmes que la normale"
    elif aplatissement > -1:
        interp_aplat = "Queues normales - Distribution classique"
    else:
        interp_aplat = "Queues lÃ©gÃ¨res - Peu d'Ã©vÃ©nements extrÃªmes"
    
    # Analyse du coefficient de variation
    if cv > 100:
        interp_cv = "TrÃ¨s forte variabilitÃ© - DonnÃ©es trÃ¨s dispersÃ©es"
    elif cv > 50:
        interp_cv = "Forte variabilitÃ© - DonnÃ©es dispersÃ©es"
    elif cv > 25:
        interp_cv = "VariabilitÃ© modÃ©rÃ©e - Dispersion acceptable"
    else:
        interp_cv = "Faible variabilitÃ© - DonnÃ©es homogÃ¨nes"
    
    st.info(f"""
    **ğŸ“‹ CaractÃ©ristiques de la Distribution :**
    
    **ğŸ”¸ AsymÃ©trie ({asymetrie:.2f}):** {interp_asym}
    
    **ğŸ”¸ Aplatissement ({aplatissement:.2f}):** {interp_aplat}
    
    **ğŸ”¸ Coefficient de Variation ({cv:.1f}%):** {interp_cv}
    
    **ğŸ¯ Conclusion :** Cette distribution est typique du risque opÃ©rationnel avec de nombreuses petites pertes et quelques pertes extrÃªmes.
    """)
    
    # Percentiles de risque
    st.subheader("ğŸ“ˆ Analyse des Percentiles de Risque")
    
    percentiles = [50, 75, 80, 85, 90, 95, 97.5, 99, 99.5, 99.9]
    valeurs_percentiles = [np.percentile(severites, p) for p in percentiles]
    
    df_percentiles = pd.DataFrame({
        'Percentile': [f"{p}%" for p in percentiles],
        'Valeur': valeurs_percentiles,
        'VaR': [f"VaR_{p}%" for p in percentiles],
        'DÃ©passement_%': [100-p for p in percentiles]
    })
    
    # Formatage
    df_percentiles['Valeur_FormatÃ©e'] = df_percentiles['Valeur'].apply(formater_montant)
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.dataframe(
            df_percentiles[['Percentile', 'Valeur_FormatÃ©e', 'DÃ©passement_%']],
            use_container_width=True
        )
    
    with col2:
        # Graphique des percentiles
        fig, ax = plt.subplots(figsize=(8, 6))
        ax.plot(percentiles, valeurs_percentiles, 'o-', linewidth=2, markersize=6)
        ax.set_xlabel('Percentiles (%)')
        ax.set_ylabel('SÃ©vÃ©ritÃ© FCFA (Ã©chelle log)')
        ax.set_title('Courbe des Percentiles (VaR)')
        ax.set_yscale('log')
        ax.grid(True, alpha=0.3)
        plt.tight_layout()
        st.pyplot(fig)
        plt.close(fig)
    
    # Distribution et histogramme
    st.subheader("ğŸ“Š Distribution des SÃ©vÃ©ritÃ©s")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Histogramme
        fig, ax = plt.subplots(figsize=(8, 6))
        ax.hist(severites, bins=50, alpha=0.7, edgecolor='black')
        ax.set_title("Histogramme des SÃ©vÃ©ritÃ©s")
        ax.set_xlabel("SÃ©vÃ©ritÃ© (FCFA)")
        ax.set_ylabel("FrÃ©quence")
        ax.grid(True, alpha=0.3)
        
        # Formatage de l'axe x en notation scientifique
        ax.ticklabel_format(style='scientific', axis='x', scilimits=(0,0))
        
        plt.tight_layout()
        st.pyplot(fig)
        plt.close(fig)
    
    with col2:
        # Box plot
        fig, ax = plt.subplots(figsize=(8, 6))
        ax.boxplot(severites)
        ax.set_title("Box Plot des SÃ©vÃ©ritÃ©s")
        ax.set_ylabel("SÃ©vÃ©ritÃ© (FCFA)")
        ax.grid(True, alpha=0.3)
        
        # Formatage de l'axe y en notation scientifique
        ax.ticklabel_format(style='scientific', axis='y', scilimits=(0,0))
        
        plt.tight_layout()
        st.pyplot(fig)
        plt.close(fig)
    
    # QQ-Plot et tests de normalitÃ©
    st.subheader("ğŸ§ª Tests de NormalitÃ© et QQ-Plots")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Tests de normalitÃ©
        try:
            # Shapiro-Wilk (Ã©chantillon si trop grand)
            sample_size = min(5000, len(severites))
            sample = np.random.choice(severites, sample_size, replace=False)
            _, p_shapiro = stats.shapiro(sample)
            
            # D'Agostino
            _, p_dagostino = stats.normaltest(severites)
            
            # Anderson-Darling
            ad_stat, ad_crit, ad_sig = stats.anderson(severites, dist='norm')
            p_anderson = 0.05 if ad_stat > ad_crit[2] else 0.10
            
            tests_normalite = pd.DataFrame({
                'Test': ['Shapiro-Wilk', 'D\'Agostino-Pearson', 'Anderson-Darling'],
                'Statistique': ['-', f"{stats.normaltest(severites)[0]:.3f}", f"{ad_stat:.3f}"],
                'P-Value': [f"{p_shapiro:.6f}", f"{p_dagostino:.6f}", f"{p_anderson:.3f}"],
                'Conclusion': [
                    'Normale' if p_shapiro > 0.05 else 'Non-Normale',
                    'Normale' if p_dagostino > 0.05 else 'Non-Normale',
                    'Normale' if p_anderson > 0.05 else 'Non-Normale'
                ]
            })
            
            st.dataframe(tests_normalite, use_container_width=True)
            
        except:
            st.warning("Tests de normalitÃ© non disponibles pour ces donnÃ©es")
    
    with col2:
        # QQ-Plot normal
        try:
            fig, ax = plt.subplots(figsize=(8, 6))
            stats.probplot(severites, dist="norm", plot=ax)
            ax.set_title("QQ-Plot vs Distribution Normale")
            ax.grid(True, alpha=0.3)
            st.pyplot(fig)
            plt.close(fig)
        except Exception as e:
            st.warning(f"QQ-Plot non disponible: {e}")
    
    # RÃ©sumÃ© final avec formatage
    st.subheader("ğŸ“‹ RÃ©sumÃ© ExÃ©cutif")
    
    # Calculs sÃ©curisÃ©s pour le rÃ©sumÃ©
    try:
        top_entite = stats_entites.index[0].replace('DGEFRI-DOF : ', '') if stats_entites is not None and len(stats_entites) > 0 else "Non disponible"
        top_categorie = stats_categories.index[0] if stats_categories is not None and len(stats_categories) > 0 else "Non disponible"
        part_top_cat = stats_categories.iloc[0]['Part_Incidents_%'] if stats_categories is not None and len(stats_categories) > 0 else 0
        
        annee_critique = "Non disponible"
        incidents_max = 0
        if trends_annuelles is not None and len(trends_annuelles) > 0:
            annee_critique = trends_annuelles['Nb_Incidents'].idxmax()
            incidents_max = trends_annuelles['Nb_Incidents'].max()
        
        st.success(f"""
        **ğŸ¯ SYNTHÃˆSE DE L'ANALYSE EXPLORATOIRE**
        
        **ğŸ“Š Volume des DonnÃ©es :**
        - {len(severites):,} incidents valides sur {nb_annees:.1f} annÃ©es
        - {df['Entite'].nunique()} entitÃ©s diffÃ©rentes
        - {df['Categorie_Risque'].nunique()} catÃ©gories de risque
        
        **ğŸ’° Profil de Risque :**
        - Perte moyenne : {formater_montant(stats_globales['Moyenne'])}
        - Perte mÃ©diane : {formater_montant(stats_globales['MÃ©diane'])}
        - Perte maximale : {formater_montant(stats_globales['Maximum'])}
        - VaR 95% : {formater_montant(np.percentile(severites, 95))}
        
        **ğŸ“ˆ CaractÃ©ristiques ClÃ©s :**
        - Distribution asymÃ©trique Ã  droite (skewness = {asymetrie:.2f})
        - Queues lourdes (kurtosis = {aplatissement:.2f})
        - Forte variabilitÃ© (CV = {cv:.1f}%)
        - Distribution typique du risque opÃ©rationnel
        
        **ğŸ† Top Risques :**
        - EntitÃ© la plus impactÃ©e : {top_entite}
        - CatÃ©gorie principale : {top_categorie} ({part_top_cat:.1f}% des incidents)
        - PÃ©riode critique : {annee_critique} ({incidents_max} incidents)
        
        **âœ… Recommandations :**
        - Utiliser des distributions spÃ©cialisÃ©es (Weibull, Log-Normale)
        - Approche LDA pour modÃ©lisation frÃ©quence/sÃ©vÃ©ritÃ©
        - Focus sur la gestion des risques extrÃªmes
        - Surveillance renforcÃ©e des entitÃ©s Ã  fort impact
        """)
    except Exception as e:
        st.error(f"âŒ Erreur dans le rÃ©sumÃ© exÃ©cutif: {e}")
        st.info("Les donnÃ©es de base sont disponibles, mais certains calculs dÃ©rivÃ©s ont Ã©chouÃ©.")
    
    return df, stats_globales

# =================== INTERFACE PRINCIPALE ===================

def main():
    """Interface principale de l'application"""
    
    st.sidebar.title("ğŸ›ï¸ Configuration")
    st.sidebar.markdown("---")
    
    # Options d'affichage
    show_details = st.sidebar.checkbox("Affichage dÃ©taillÃ©", value=True)
    show_graphs = st.sidebar.checkbox("Graphiques avancÃ©s", value=True)
    
    # Bouton de lancement
    if st.sidebar.button("ğŸš€ LANCER L'ANALYSE", type="primary"):
        with st.spinner("Analyse en cours..."):
            try:
                df, stats = analyse_exploratoire_complete()
                
                if df is not None:
                    st.balloons()
                    st.sidebar.success("âœ… Analyse terminÃ©e !")
                    
                    # TÃ©lÃ©chargement des rÃ©sultats
                    if st.sidebar.button("ğŸ“¥ TÃ©lÃ©charger Rapport"):
                        # Conversion en CSV pour tÃ©lÃ©chargement
                        csv = df.to_csv(index=False)
                        st.sidebar.download_button(
                            label="ğŸ“„ TÃ©lÃ©charger CSV",
                            data=csv,
                            file_name=f"analyse_oprisk_{pd.Timestamp.now().strftime('%Y%m%d_%H%M')}.csv",
                            mime="text/csv"
                        )
            except Exception as e:
                st.error(f"âŒ Erreur lors de l'analyse: {e}")
                st.info("ğŸ” VÃ©rifiez que le fichier base_incidents.xlsx est prÃ©sent dans le bon format")
    else:
        st.info("ğŸ‘ˆ Utilisez le panneau latÃ©ral pour lancer l'analyse")
        
        # Informations sur l'application
        st.markdown("""
        ## ğŸ“‹ Ã€ propos de cette analyse
        
        Cette application fournit une **analyse exploratoire complÃ¨te** des donnÃ©es de risque opÃ©rationnel, avec affichage des vraies valeurs en FCFA :
        
        **ğŸ—‚ï¸ Structure de DonnÃ©es DÃ©tectÃ©e :**
        - Code d'incident
        - EntitÃ© (DGEFRI-DOF)
        - GravitÃ© (TrÃ¨s faible, Faible, Fort, etc.)
        - CatÃ©gorie de Risque (RF, RSI, RH, etc.)
        - CoÃ»t total estimÃ© (converti automatiquement en FCFA rÃ©els)
        - Date de survenance (format DD-MM-YYYY)
        
        **ğŸ’° Formatage Intelligent :**
        - Affichage automatique en k FCFA, M FCFA, ou Md FCFA
        - Conversion transparente des donnÃ©es stockÃ©es en unitÃ©s de 10 000 FCFA
        - Graphiques et tableaux avec vraies valeurs
        
        **1ï¸âƒ£ CaractÃ©ristiques GÃ©nÃ©rales**
        - Vue d'ensemble des donnÃ©es avec vraies valeurs
        - Statistiques dÃ©taillÃ©es par entitÃ©
        - MÃ©triques de concentration du risque
        
        **2ï¸âƒ£ Distribution par CatÃ©gorie et GravitÃ©**
        - Analyse par catÃ©gorie de risque (RF, RSI, RH, etc.)
        - RÃ©partition par niveau de gravitÃ©
        - Matrices de corrÃ©lation
        
        **3ï¸âƒ£ Tendances Temporelles**
        - Ã‰volution annuelle et mensuelle
        - Tests de saisonnalitÃ©
        - DÃ©tection statistique de tendances
        
        **4ï¸âƒ£ Statistiques de SÃ©vÃ©ritÃ©**
        - Statistiques descriptives complÃ¨tes avec formatage
        - Percentiles de risque (VaR) en vraies valeurs
        - Tests de normalitÃ© et QQ-Plots
        
        **ğŸ“Š DonnÃ©es Attendues :**
        - Fichier : `base_incidents.xlsx`
        - Feuille : `Incidents_DOF_augmente`
        - Format dÃ©tectÃ© automatiquement
        - Conversion automatique en FCFA rÃ©els
        """)

if __name__ == "__main__":
    main()